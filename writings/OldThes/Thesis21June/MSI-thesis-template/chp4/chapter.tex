\chapter{Linear Analysis of Numerical Methods}
\label{chp:AnalNumMethod}
An important property of a numerical method is convergence. Convergence guarantees that as we increase the spatial and temporal resolution of a numerical method, its numerical solution approaches the solution of the partial differential equations. For linear partial differential equations the Lax-equivalence theorem states that a numerical method is convergent if and only if it is stable and consistent \cite{Lax-Richtmyer-1956-267}. A numerical scheme is consistent if the error introduced by the numerical method over a time step approaches zero as the spatial and temporal resolution is increased. While a numerical method is stable if the errors from previous time steps are not amplified by the current time step.

Another important property of a numerical method modelling dispersive wave equations such as the Serre equations is its dispersion properties. The dispersion relation of a system determines the phase and group velocity of travelling waves in that system. The Serre equations possess a dispersion relation that well approximates the dispersion relation given by linear theory for water waves []. Therefore, how well the dispersion relation of our numerical methods approximate the dispersion relation of the Serre equations is of particular interest.

We analysed the convergence and the dispersion properties of our numerical methods for the linearised Serre equations with horizontal beds. The dispersion relation for the Serre equations is derived from the linearised Serre equations, with variations in the bed having no effect []. Therefore this is the most extensive analysis of the dispersion relation of our numerical methods that can be performed. For the convergence analysis the effect of variations in the bed and nonlinear terms are important but these effects increase the complexity of the analysis significantly. We study the linearised Serre equations with horizontal beds to offer some insight into the convergence properties of these methods without having to deal with these issues. In general we would expect that a numerical method that performs poorly for the linearised Serre equations will also perform poorly for their nonlinear counterparts.

These linear analyses of convergence and dispersion rely on establishing a relationship of the form

\begin{equation}
\label{eqn:linearanalaim}
\begin{bmatrix}
h \\G
\end{bmatrix}^{n+1}_j = \matr{E} \begin{bmatrix}
h \\G
\end{bmatrix}^{n}_j
\end{equation}
 where $\matr{E}$ is the evolution matrix relating the conserved quantities $h$ and $G$ at time level $t^n$ with the conserved quantities at time level $t^{n+1}$. The evolution matrix $\matr{E}$ is obtained in the analyses by propagating Fourier modes through the numerical scheme. From \eqref{eqn:linearanalaim} the convergence and dispersion analysis become an analysis of the properties of $\matr{E}$.
 
 We begin our analyses by giving the linearised Serre equations with horizontal beds. We then derive $\matr{E}$ \eqref{eqn:linearanalaim} for the second-order FEVM and perform the convergence and dispersion analysis. We will then present the results of these analyses for all our numerical methods.
 
\section{Linearised Serre equations with horizontal bed}
The Serre equations with a horizontal bed \eqref{eqn:FullSerreNonConHorizbed} are linearised by considering waves as small perturbations $\delta\eta$ and $\delta\upsilon$ on a flow with a mean height $H$ and a mean velocity $U$ respectively. So we have
\begin{subequations}
	\label{eq:pertubation}
\begin{align}
h(x,t) &= H + \delta \eta(x,t) + \mathcal{O}\left(\delta^2 \right), \\
u(x,t) &= U + \delta \upsilon(x,t) + \mathcal{O}\left(\delta^2 \right),
\end{align}
\end{subequations}
where $\delta \ll 1$. These waves are relatively small so terms of order $\delta^2$ are negligible. We substitute \eqref{eq:pertubation} into the Serre equations and neglect terms of order $\delta^2$ to obtain

\begin{subequations}
	\begin{align}
		\label{eqn:LinCont}
		&\frac{\partial  \left(\delta\eta \right)}{\partial  t} + H\frac{\partial  \left(\delta\upsilon \right)}{\partial  x} + U\frac{\partial  \left(\delta\eta \right)}{\partial  x}  = 0, \\
	\label{eqn:LineMome}
	&H\frac{\partial  \left(\delta\upsilon \right)}{\partial  t} + gH\frac{\partial  \left(\delta\eta \right)}{\partial  x} + UH\frac{\partial  \left(\delta\upsilon \right)}{\partial  x} - \frac{H^3}{3}\left(U\frac{\partial^3  \left(\delta\upsilon \right)}{\partial  x^3} + \frac{\partial^3  \left(\delta\upsilon \right)}{\partial  x^2 \partial  t}  \right)  = 0
	\end{align}	
and for $G$
\begin{equation}
	G = UH + U \delta \eta + H \delta \upsilon -\frac{H^3}{3} \frac{\partial^2 \left(\delta\upsilon \right)}{\partial x^2}.
\end{equation}	
	\label{eqn:LinConSerre}
\end{subequations}
These equations can be reformulated in terms of the conserved quantities $\eta$ and $G$
\begin{subequations}
	\begin{align}
	\label{eqn:LinContG}
	&\frac{\partial  \eta}{\partial  t} +\frac{\partial}{\partial  x} \left(H\upsilon + U \eta\right) = 0, \\
	\label{eqn:LineMomeG}
	&\frac{\partial  G}{\partial  t} + \frac{\partial}{\partial  x}\left(UG + UH\upsilon + gH \eta\right) = 0.
	\end{align}
	where
	\begin{equation}
	G = UH + U \eta + H \upsilon -\frac{H^3}{3} \frac{\partial^2 \left(\upsilon \right)}{\partial x^2}.
	\label{eqn:LinConSerreG}
	\end{equation}
	\label{eqn:LinSerreG}	
\end{subequations}
We have absorbed the $\delta$ factor into the corresponding $\eta$ and $\upsilon$ terms to simplify the notation.

\section{Evolution Matrix}
To derive the evolution matrix we first assume that the solutions of the linearised Serre equations with horizontal beds \eqref{eqn:LinSerreG} are periodic in space and time. In particular, we assume that $\eta$ and $\upsilon$ are Fourier modes, which for a general quantity $q$ means
\begin{equation}
q(x,t) = q(0,0) e^{i\left(\omega t + kx\right)}.
\label{eqn:FourierNode}
\end{equation}
This is precisely the assumption made to derive the analytical dispersion relation of the linearised Serre equations []. A consequence of a quantity $q$ being a Fourier mode represented on a uniform temporal and spatial grid is that for any real numbers $m$ and $l$ we have
\begin{equation}
q^{n + m}_{j + l} = q^n_j e^{ i \left(m \omega \Delta t + l k \Delta x\right)}.
\label{eqn:fourierfactor}
\end{equation}
Because $\eta$ and $\upsilon$ are Fourier modes then so is $G$. Furthermore, the cell averages of these quantities $\overline{\eta}$, $\overline{\upsilon}$ and $\overline{G}$ are Fourier modes as well.

\subsection{Overview of the Evolution Step}
We will now present a brief overview of a single evolution step of the second-order FEVM. Given the vectors of the cell averages $\overline{\vecn{\eta}}$ and $\overline{\vecn{G}}$ at the current time the second-order FEVM evolution step progresses in the following way
\begin{enumerate}
	\item Reconstruction: We use the operator $\mathcal{M}$ to calculate $\eta$ and $G$ at the cell midpoint $x_{j}$ from the cell averages. We also reconstruct $\eta$ and $G$ at the cell interfaces $x^-_{j+1/2}$ and $x^+_{j+1/2}$ from the cell average values using $\mathcal{R}^{-}$ and $\mathcal{R}^{+}$ respectively. So that
	\begin{align*}	&\eta_j = \mathcal{M}\left(\overline{\vecn{\eta}}\right),&& G_j = \mathcal{M}\left(\overline{\vecn{G}}\right),\\
	&\eta^-_{j+1/2} = \mathcal{R}^{-}\left(\overline{\vecn{\eta}}\right),  &&G^-_{j+1/2} = \mathcal{R}^{-}\left(\overline{\vecn{G}}\right), \\
	&\eta^+_{j+1/2} = \mathcal{R}^{+}\left(\overline{\vecn{\eta}}\right),  &&G^+_{j+1/2} = \mathcal{R}^{+}\left(\overline{\vecn{G}}\right). \\	
	\end{align*}
	\item Calculate $\upsilon$: The remaining unknown quantity, $\upsilon_{j+1/2}$ is calculated from the solution of the elliptic equation \eqref{eqn:LinConSerreG}. This calculation is represented by $\mathcal{G}$ as
	\begin{equation*}
	\upsilon_{j+1/2} = \mathcal{G}\left(H, {\vecn{G}},{\vecn{\eta}}\right).
	\end{equation*}
	\item Calculate Flux: We calculate the average flux $F_{j+1/2}$ across the cell boundary
	 $x_{j+1/2}$ over time using $\mathcal{F}$
 	\begin{equation*}
 	F_{j+1/2} =\mathcal{F} \left(\eta^-_{j+1/2}, G^-_{j+1/2},\eta^+_{j+1/2}, G^+_{j+1/2},\upsilon_{j+1/2}  \right). 
 	\end{equation*}
	\item Forward Euler Step: We repeat this process for each cell edge and then apply \eqref{eqn:evolupdatescheme} to update the vectors $\overline{\vecn{\eta}}$ and $\overline{\vecn{G}}$ from the current time level to the next time level with first-order accuracy in time.
	\item SSP Runge-Kutta Steps: We repeat steps 1-4 and use SSP Runge-Kutta time stepping to calculate $\overline{\vecn{\eta}}$ and $\overline{\vecn{G}}$ at the next time level with second-order accuracy in time.
\end{enumerate}

We will now derive expressions for all the operators in the evolution step, which will be linear due to our assumption that $\eta$ and $\upsilon$ are Fourier modes. We will then combine these linear operators to derive $\matr{E}$ for the second-order FEVM.

\subsection{1. Reconstruction}
Given $\overline{\vecn{\eta}}$ and $\overline{\vecn{G}}$ at $t^n$ the first step of our numerical method is to calculate $\eta$ and $G$ at $x_j$ using $\mathcal{M}$ and at $x^-_{j+1/2}$ and $x^+_{j+1/2}$ using $\mathcal{R}^-$ and $\mathcal{R}^+$ respectively. The derivation of these operators is given in terms of a general quantity $q$, as they are the same for $\eta$ and $G$.
\subsubsection{Cell average values to nodal values: $\mathcal{M}$}
For the second-order FEVM we use the fact that
\begin{equation*}
\overline{q}_j =q_j  + \mathcal{O}\left(\Delta x^2\right).
\end{equation*}
%
So to attain second-order accuracy we use
%
\begin{equation}
\label{eqn:Mfactorfourier}
q_j = \overline{q}_j  = \mathcal{M} \overline{q}_j.
\end{equation}
Therefore, we have a factor $\mathcal{M}=1$ representing the map between cell averages and nodal values for our numerical method.

\subsubsection{Cell average values to interface values: $\mathcal{R}^-$ and $\mathcal{R}^+$}

We reconstruct $\eta$ and $G$ at $x^-_{j+1/2}$ and $x^+_{j+1/2}$. These quantities can be discontinuous across the cell interfaces in our finite volume method. However, since we are assuming that these quantities are Fourier modes and therefore smooth we do not require non-linear limiters to ensure our scheme is TVD. Without limiters our reconstruction scheme for $\eta$ and $G$ can be written for a general quantity $q$ as

\begin{equation*}
q^-_{j+\frac{1}{2}} = \overline{q}_j + \frac{- \overline{q}_{j - 1} + \overline{q}_{j+ 1} }{4},
\end{equation*}
\begin{equation*}
q^+_{j+\frac{1}{2}} = \overline{q}_{j+1} + \frac{- \overline{q}_{j} + \overline{q}_{j+ 2}}{4}.
\end{equation*}

Using \eqref{eqn:fourierfactor} and \eqref{eqn:Mfactorfourier} these equations become

\begin{subequations}
	\label{eqn:RpmfactorFDVM}
	\begin{align}
	&q^-_{j+\frac{1}{2}} =\overline{q}_j + \frac{- \overline{q}_{j} e^{-ik\Delta x} + \overline{q}_{j} e^{ik\Delta x}}{4} = \left(1  + \frac{i\sin\left(k\Delta x\right)}{2} \right)\overline{q}_{j} =\mathcal{R}^- \overline{q}_{j},\\
	&q^+_{j+\frac{1}{2}}= \frac{\overline{q}_{j}e^{ik\Delta x} + \overline{q}_{j} + \overline{q}_{j}e^{2ik\Delta x} }{4} = e^{ik\Delta x}\left(1  - \frac{i\sin\left(k\Delta x\right)}{2} \right)\overline{q}_{j} = \mathcal{R}^+ \overline{q}_{j}.
	\end{align}
\end{subequations}
These are the reconstruction factors for both $\eta^{\pm}_{j+1/2}$ and $G^{\pm}_{j+1/2}$.

\subsection{2. Calculate $\upsilon$}
To calculate $\upsilon_{j+1/2}$ we use a second-order FEM. We begin our FEM for \eqref{eqn:LinConSerreG} with its weak formulation, obtained by multiplying \eqref{eqn:LinConSerreG} by a test function $\tau$ and integrating over the domain $\Omega$
\begin{equation*}
\int_{\Omega}G \tau \; dx = UH\int_{\Omega} \tau \; dx + U \int_{\Omega} \eta \tau \; dx +   H\int_{\Omega} \upsilon \tau \; dx  + \frac{H^3}{3} \int_{\Omega} \frac{\partial \upsilon}{\partial x } \frac{\partial \tau}{\partial x }\; dx.
\end{equation*}
For $G$ we use the basis functions $\psi^+_{j - 1/2}$ and $\psi^-_{j + 1/2}$ defined in Chapter [], which means our approximation to $G$ is linear inside a cell with discontinuous jumps at the cell edges. For $\tau$ and $\upsilon$ we use the basis functions $\phi_{j-1/2}$, $\phi_{j}$ and $\phi_{j+1/2}$ defined in Chapter [], so that $\tau$ and our approximation to $\upsilon$ are quadratic functions inside a cell that are continuous across the cell edges. Substituting in the approximations to our quantities based on these basis functions and breaking our integration up into the sum of the integrals over a cell as we did in Chapter [], we get

\begin{multline*}
\sum_j \int_{x_{j-1/2}}^{x_{j + 1/2}} \left(G^+_{j-1/2}\psi^+_{j - 1/2} + G^-_{j+1/2}\psi^-_{j + 1/2}\right) \begin{bmatrix}
\phi_{j-1/2}\\\phi_j \\\phi_{j+1/2}
\end{bmatrix}  \; dx =  \\ \sum_j UH\int_{x_{j-1/2}}^{x_{j + 1/2}}  \begin{bmatrix}
\phi_{j-1/2}\\\phi_j \\\phi_{j+1/2}
\end{bmatrix}  \; dx + \sum_j U\int_{x_{j-1/2}}^{x_{j + 1/2}} \left(\eta^+_{j-1/2}\psi^+_{j - 1/2} + \eta^-_{j+1/2}\psi^-_{j + 1/2}\right) \begin{bmatrix}
\phi_{j-1/2}\\\phi_j \\\phi_{j+1/2}
\end{bmatrix}  \; dx \\   +\sum_j H\int_{x_{j-1/2}}^{x_{j + 1/2}} \left(\upsilon_{j-1/2}\phi_{j - 1/2} + \upsilon_{j}\phi_{j}+ \upsilon_{j+1/2}\phi_{j + 1/2}\right) \begin{bmatrix}
\phi_{j-1/2}\\\phi_j \\\phi_{j+1/2}
\end{bmatrix}  \; dx \\ + 
\sum_j \frac{H^3}{3}\int_{x_{j-1/2}}^{x_{j + 1/2}} \left(\upsilon_{j-1/2} \frac{\partial \phi_{j - 1/2} }{\partial x} + \upsilon_{j}\frac{\partial \phi_{j} }{\partial x}+ \upsilon_{j+1/2}\frac{\partial \phi_{j + 1/2} }{\partial x}\right) \begin{bmatrix}
\dfrac{\partial \phi_{j - 1/2} }{\partial x}\\ \\\dfrac{\partial \phi_{j} }{\partial x}\\ \\\dfrac{\partial \phi_{j + 1/2} }{\partial x}   \end{bmatrix} \; dx.
\end{multline*}
Calculating all the integrals of the appropriate basis function combinations we get 
\begin{multline*}
\sum_j \frac{\Delta x}{6}\begin{bmatrix} G^+_{j -1/2} \\2 G^+_{j -1/2}+2 G^-_{j +1/2} \\ G^-_{j +1/2} \end{bmatrix} = \sum_jUH \frac{\Delta x}{6}\begin{bmatrix} 1 \\4 \\ 1 \end{bmatrix} +  \sum_j \frac{\Delta x}{6}U\begin{bmatrix} \eta^+_{j -1/2} \\2 \eta^+_{j -1/2}+2 \eta^-_{j +1/2} \\ \eta^-_{j +1/2} \end{bmatrix}\\ + \sum_j \left(H\frac{\Delta x}{30}\begin{bmatrix} 4 &2 &-1 \\2 &16 &2  \\-1 &2 &4 \end{bmatrix} + \frac{H^3 }{9\Delta x}\begin{bmatrix} 7 &-8 &1  \\-8 &16 &-8  \\1 &-8 &7  \end{bmatrix} \right) \begin{bmatrix} \upsilon_{j -1/2} \\\upsilon_{j} \\ \upsilon_{j +1/2} \end{bmatrix}.
\end{multline*} 
%minmod limiter for G
Using \eqref{eqn:fourierfactor} and the reconstructions $\mathcal{R}^+$ and $\mathcal{R}^-$ \eqref{eqn:RpmfactorFDVM} used on $\overline{G}$ to obtain $G^+_{j +1/2}$ and $G^-_{j +1/2}$ respectively, we obtain

\begin{multline*}
\sum_j \frac{\Delta x}{6} \begin{bmatrix} e^{-ik\Delta x} \mathcal{R}^+ \overline{G}_{j} \\2 e^{-ik\Delta x} \mathcal{R}^+\overline{G}_{j} +2 \mathcal{R}^- \overline{G}_{j}\\ \mathcal{R}^- \overline{G}_{j} \end{bmatrix} =   \sum_jUH \frac{\Delta x}{6}\begin{bmatrix} 1 \\4 \\ 1 \end{bmatrix} \\+  \sum_j \frac{\Delta x}{6} U \begin{bmatrix} e^{-ik\Delta x} \mathcal{R}^+ \overline{\eta}_{j} \\2 e^{-ik\Delta x} \mathcal{R}^+\overline{\eta}_{j} +2 \mathcal{R}^- \overline{\eta}_{j}\\ \mathcal{R}^- \overline{\eta}_{j} \end{bmatrix}  \\\sum_j \left(H\frac{\Delta x}{30}\begin{bmatrix} 4 &2 &-1 \\2 &16 &2  \\-1 &2 &4 \end{bmatrix} + \frac{H^3 }{9\Delta x}\begin{bmatrix} 7 &-8 &1  \\-8 &16 &-8  \\1 &-8 &7  \end{bmatrix} \right) \begin{bmatrix} e^{-ik\frac{\Delta x}{2}}\upsilon_{j} \\\upsilon_{j} \\ e^{ik\frac{\Delta x}{2}}\upsilon_{j}. \end{bmatrix}
\end{multline*}
After simplifying
\begin{multline*}
\sum_j \frac{\Delta x}{6}\begin{bmatrix} e^{-ik\Delta x} \mathcal{R}^+ \\2 e^{-ik\Delta x} \mathcal{R}^+ +2 \mathcal{R}^-\\ \mathcal{R}^- \end{bmatrix} \overline{G}_{j} = \sum_jUH \frac{\Delta x}{6}\begin{bmatrix} 1 \\4 \\ 1 \end{bmatrix}  \\+  \sum_j \frac{\Delta x}{6}\begin{bmatrix} e^{-ik\Delta x} \mathcal{R}^+ \\2 e^{-ik\Delta x} \mathcal{R}^+ +2 \mathcal{R}^-\\ \mathcal{R}^- \end{bmatrix} \overline{\eta}_{j}  + \sum_j \Bigg(H\frac{\Delta x}{30}\begin{bmatrix} 4e^{-ik\frac{\Delta x}{2}} +  2 - e^{ik\frac{\Delta x}{2}}\\2e^{-ik\frac{\Delta x}{2}}  + 16  +2 e^{ik\frac{\Delta x}{2}}  \\ -e^{-ik\frac{\Delta x}{2}} +  2 + 4e^{ik\frac{\Delta x}{2}} \end{bmatrix} \\+ \frac{H^3 }{9\Delta x}\begin{bmatrix} 7e^{-ik\frac{\Delta x}{2}} -8 + e^{ik\frac{\Delta x}{2}} \\ -8e^{-ik\frac{\Delta x}{2}} +  16  -8e^{ik\frac{\Delta x}{2}} \\ e^{-ik\frac{\Delta x}{2}} -8 + 7e^{ik\frac{\Delta x}{2}} \end{bmatrix}  \Bigg) \upsilon_j.
\end{multline*}
These vectors represent three equations for the $j^{th}$ cell, the first relates $\overline{G}_j$ to $\upsilon_{j-1/2}$, the second relates $\overline{G}_j$ to $\upsilon_{j}$ and the third relates $\overline{G}_j$ to $\upsilon_{j+1/2}$. Since we are calculating $\upsilon_{j+1/2}$ we only need to solve  the third equation. So far we have only given the contribution to $\upsilon_{j+1/2}$ from the $j$th cell, but there is also a contribution from the $(j+1)$th cell as $\phi_{j+1/2}$ non-zero over it. Accounting for this we get
\begin{align*}
\frac{\Delta x}{6} \left(\mathcal{R}^- + \mathcal{R}^+ \right)\overline{G}_{j} &= \frac{\Delta x}{6} 2UH   + \frac{\Delta x}{6} U \left(\mathcal{R}^- + \mathcal{R}^+ \right)\overline{\eta}_{j} \\ & \quad \Bigg(H\frac{\Delta x}{30} \left( -e^{-ik\frac{\Delta x}{2}} +  2 + 4e^{ik\frac{\Delta x}{2}} + e^{ik{\Delta x}}\left(4e^{-ik\frac{\Delta x}{2}} +  2 - e^{ik\frac{\Delta x}{2}}\right) \right)  \\ & \quad + \frac{H^3 }{9\Delta x} \left(  e^{-ik\frac{\Delta x}{2}} -8 + 7e^{ik\frac{\Delta x}{2}}  + e^{ik{\Delta x}}\left(7e^{-ik\frac{\Delta x}{2}} -8 + e^{ik\frac{\Delta x}{2}}  \right)  \right)   \Bigg) \upsilon_j
 \\ \\ &= \frac{\Delta x}{3}UH   + \frac{\Delta x}{6} U \left(\mathcal{R}^- + \mathcal{R}^+ \right)\overline{\eta}_{j}  \\ & \quad +  \Bigg[H\frac{\Delta x}{30} \left( 4\cos\left(\frac{k \Delta x}{2}\right) - 2\cos\left({k \Delta x}\right) + 8\right)   \\ & \quad + \frac{H^3 }{9\Delta x} \left(-16\cos\left(\frac{k\Delta x}{2}\right) + 2 \cos\left(k \Delta x\right) + 14\right) \Bigg]e^{i k \frac{\Delta x}{2}} \upsilon_{j}.
\end{align*}
Since $\upsilon_{j+1/2} = e^{i k \frac{\Delta x}{2}} \upsilon_{j} $ \eqref{eqn:fourierfactor} we have 
\begin{align}
\label{eqn:2ndFEMutoG}
\upsilon_{j+1/2} &=  \left[\left(\frac{\Delta x}{6} \left(\mathcal{R}^- + \mathcal{R}^+ \right)\right)  \overline{G}_{j}  - \frac{\Delta x}{3}UH - U\left(\frac{\Delta x}{6} \left(\mathcal{R}^- + \mathcal{R}^+ \right)\right)  \overline{\eta}_{j}   \right] \nonumber\\
& \quad  \div  \Bigg[H\frac{\Delta x}{30} \left( 4\cos\left(\frac{k \Delta x}{2}\right) - 2\cos\left({k \Delta x}\right) + 8\right)  \nonumber\\ & \quad + \frac{H^3 }{9\Delta x}\left(-16\cos\left(\frac{k\Delta x}{2}\right) + 2 \cos\left(k \Delta x\right) + 14\right)    \Bigg]
\nonumber \\ \nonumber\\ &=  \mathcal{G}^G \overline{G}_{j} + \mathcal{G}^{\eta} \overline{\eta}_{j} + \mathcal{G}^c .
\end{align}
 

\subsection{3. Flux calculation}
To calculate the average flux $F_{j+1/2}$ we use Kurganov's method \cite{Kurganov-etal-2001-707}. For the linearised Serre equations we have the wave speed bounds \eqref{eqn:WaveVelocitiesBound}, so that
\begin{align}
a^-_{j+ 1/2} = \min \left\lbrace 0,  U - \sqrt{g H} \right \rbrace& &\text{and}& &a^+_{j+ 1/2} =  \max \left\lbrace 0, U + \sqrt{g H} \right \rbrace .
\label{eqn:wavespeedboundslinSerre}
\end{align}

This method has three different approximations to $F_{j+1/2}$ depending on $U$, $g$ and $H$;  supercritical flow to the left $U < - \sqrt{gH}$, subcritical flow $-\sqrt{gH} \le U \le \sqrt{gH}$ and supercritical flow to the right $\sqrt{gH} < U$. We will derive the flux operators for each of these scenarios separately.

\subsubsection{Left supercritical flow $U < - \sqrt{gH}$:}
For left supercritical flow; $U < - \sqrt{gH}$  we have from \eqref{eqn:wavespeedboundslinSerre} that $a^-_{j+ 1/2} = U - \sqrt{g H}$ and $a^+_{j+ 1/2} =  0$. For these values the Kurganov flux approximation for a general quantity $q$ [] reduces to 
\begin{equation}
F_{j+\frac{1}{2}} = f\left(q^+_{j+\frac{1}{2}}\right).
\label{eqn:fluxleftsupercrit}
\end{equation}

Substituting the flux function for $\eta$ \eqref{eqn:LinContG} into the Kurganov flux approximation \eqref{eqn:fluxleftsupercrit} we obtain
\begin{equation*}
F^\eta_{j+\frac{1}{2}} = H \upsilon_{j+1/2} + U \eta^+_{j+1/2}
\end{equation*}
since $\upsilon$ is continuous and therefore $\upsilon_{j+1/2} = \upsilon_{j+1/2}^+ = \upsilon_{j+1/2}^- $. Using the FEM for $\upsilon_{j+1/2}$ \eqref{eqn:2ndFEMutoG} and the reconstruction \eqref{eqn:RpmfactorFDVM} we have
\begin{align}
F^\eta_{j+\frac{1}{2}} &= H \left(\mathcal{G}^G \overline{G}_{j} + \mathcal{G}^{\eta} \overline{\eta}_{j} + \mathcal{G}^c\right) + U \eta^+_{j+1/2} \nonumber \\ &= \left(H \mathcal{G}^{\eta} + U \mathcal{R}^+ \right)  \overline{\eta}_{j} + H \mathcal{G}^G \overline{G}_{j} + H\mathcal{G}^c \nonumber \\
&= F^{\eta, \eta}_{j+\frac{1}{2}} \overline{\eta}_{j} + F^{\eta, G}_{j+\frac{1}{2}} \overline{G}_{j} + F^{\eta, c}_{j+\frac{1}{2}}
\label{eqn:Fluxfactorsupercritetaleft}
\end{align}

Substituting the flux function for $G$ \eqref{eqn:LineMomeG} into the Kurganov flux approximation \eqref{eqn:fluxleftsupercrit} we obtain
\begin{equation*}
F^G_{j+\frac{1}{2}} =U G^+_{j+1/2} + U  H \upsilon_{j+1/2} + gH \eta^+_{j+1/2}
\end{equation*}
Using the FEM to calculate $\upsilon_{j+1/2}$ \eqref{eqn:2ndFEMutoG} and our interface reconstruction \eqref{eqn:RpmfactorFDVM} we have
\begin{align}
F^G_{j+\frac{1}{2}} &=  U G^+_{j+1/2} + UH \left(\mathcal{G}^G \overline{G}_{j} + \mathcal{G}^{\eta} \overline{\eta}_{j} + \mathcal{G}^c\right) + gH \eta^+_{j+1/2} \nonumber \\ &= \left(UH \mathcal{G}^{\eta} + gH \mathcal{R}^+ \right)  \overline{\eta}_{j} + \left(U\mathcal{R}^+  +  UH \mathcal{G}^G \right) \overline{G}_{j} + UH\mathcal{G}^c \nonumber \\
&= F^{G, \eta}_{j+\frac{1}{2}} \overline{\eta}_{j} + F^{G, G}_{j+\frac{1}{2}} \overline{G}_{j} + F^{G, c}_{j+\frac{1}{2}}
\label{eqn:FluxfactorsupercritGleft}
\end{align}


\subsubsection{Subcritical flow $-\sqrt{gH} \le U \le \sqrt{gH}$:}
When the flow is subcritical we have $-\sqrt{gH} \le U \le \sqrt{gH}$, which means that $a^-_{j+ 1/2} = U - \sqrt{g H}$ and $a^+_{j+ 1/2} =  U + \sqrt{g H}$. Therefore Kurganov flux approximation for a general quantity $q$ [] is

\begin{align}
F_{j+\frac{1}{2}} &= \frac{U}{2 \sqrt{gH}} \left[f\left(q^-_{j+\frac{1}{2}}\right) - f\left(q^+_{j+\frac{1}{2}}\right) \right]  + \frac{1}{2}\left[f\left(q^-_{j+\frac{1}{2}}\right) + f\left(q^+_{j+\frac{1}{2}}\right)\right] \nonumber \\ & \quad  + \dfrac{U^2 - gH}{2\sqrt{g H}} \left [ q^+_{j+\frac{1}{2}} - q^-_{j+\frac{1}{2}} \right ].
\label{eqn:fluxsubcrit}
\end{align}

Substituting in the flux function for $\eta$ \eqref{eqn:LinContG} into \eqref{eqn:fluxsubcrit} we get
\begin{align}
F^\eta_{j+\frac{1}{2}} &= \frac{U}{2 \sqrt{gH}} \left[ H\upsilon_{j+1/2} + U\eta^-_{j+\frac{1}{2}} -  H\upsilon_{j+1/2} - U \eta^+_{j+\frac{1}{2}} \right]   \nonumber \\ & \quad + \frac{1}{2}\left[H\upsilon_{j+1/2} + U\eta^-_{j+\frac{1}{2}} +  H\upsilon_{j+1/2} + U \eta^+_{j+\frac{1}{2}}\right] \nonumber \\ &\quad + \dfrac{U^2 - gH}{2\sqrt{g H}} \left [ \eta^+_{j+\frac{1}{2}} - \eta^-_{j+\frac{1}{2}} \right ].
\end{align}
Using the reconstruction factors \eqref{eqn:RpmfactorFDVM} and the elliptic solver \eqref{eqn:2ndFEMutoG} we get
\begin{align}
F^\eta_{j+\frac{1}{2}} &= \left(H\mathcal{G}^{\eta}  + \frac{U}{2}\left[ \mathcal{R}^- +  \mathcal{R}^+\right]- \dfrac{\sqrt{gH}}{2} \left [ \mathcal{R}^+ - \mathcal{R}^- \right ] \right) \overline{\eta}_j \nonumber \\  &\quad + H\mathcal{G}^G \overline{G}_{j} + H \mathcal{G}^c \nonumber \\ &= F^{\eta, \eta}_{j+\frac{1}{2}} \overline{\eta}_{j} + F^{\eta, G}_{j+\frac{1}{2}} \overline{G}_{j} + F^{\eta, c}_{j+\frac{1}{2}} .
\label{eqn:Fluxfactorsubcriteta}
\end{align}

For the flux function of $G$ \eqref{eqn:LineMomeG} the flux approximation \eqref{eqn:fluxsubcrit} becomes
\begin{align}
F^G_{j+\frac{1}{2}} &= \frac{U}{2 \sqrt{gH}} \left[ UG^-_{j+\frac{1}{2}} + UH \upsilon_{j+1/2} + gH\eta^-_{j+\frac{1}{2}} - UG^+_{j+\frac{1}{2}} - UH \upsilon_{j+1/2} - gH\eta^+_{j+\frac{1}{2}}  \right]   \nonumber \\ & \quad + \frac{1}{2}\left[UG^-_{j+\frac{1}{2}} + UH \upsilon_{j+1/2} + gH\eta^-_{j+\frac{1}{2}} + UG^+_{j+\frac{1}{2}} + UH \upsilon_{j+1/2} + gH\eta^+_{j+\frac{1}{2}}\right] \nonumber \\ & \quad+ \dfrac{U^2 - gH}{2\sqrt{g H}} \left [ G^+_{j+\frac{1}{2}} - G^-_{j+\frac{1}{2}} \right ].
\end{align}
By using the reconstruction factors \eqref{eqn:RpmfactorFDVM} and the elliptic solver \eqref{eqn:2ndFEMutoG} we get
\begin{align}
F^G_{j+\frac{1}{2}} &= \left(\frac{U\sqrt{gH}}{2} \left[ \mathcal{R}^- - \mathcal{R}^+  \right] + UH\mathcal{G}^{\eta} + \frac{gH}{2} \left[ \mathcal{R}^- +\mathcal{R}^+ \right]   \right)\overline{\eta}_j \nonumber \\ & \quad+ \left(UH\mathcal{G}^{G} + + \frac{U}{2} \left[ \mathcal{R}^- +\mathcal{R}^+ \right] - \dfrac{\sqrt{g H}}{2} \left [\mathcal{R}^+ - \mathcal{R}^- \right ]   \right) \overline{G}_j + UH\mathcal{G}^{c}  \nonumber \\
& = F^{G, \eta}_{j+\frac{1}{2}} \overline{\eta}_{j} + F^{G, G}_{j+\frac{1}{2}} \overline{G}_{j} + F^{G, c}_{j+\frac{1}{2}}   .
\label{eqn:FluxfactorsubcritG}
\end{align}




\subsubsection{Right supercritical flow $\sqrt{gH} < U$:}
When the flow is flowing to the right and supercritical we have $ \sqrt{gH} < U $, which means that $a^-_{j+ 1/2} = 0$ and $a^+_{j+ 1/2} =  U + \sqrt{g H}$. This is very similar to the left supercritical case, except instead of using the $\mathcal{R}^+$ we have $\mathcal{R}^-$ as our flux update for a general quantity reduces to
\begin{equation}
F_{j+\frac{1}{2}} = f\left(q^-_{j+\frac{1}{2}}\right).
\label{eqn:fluxsupercritright}
\end{equation}
Substituting in the flux function for $\eta$ \eqref{eqn:LinContG} into \eqref{eqn:fluxsupercritright} we obtain
\begin{align}
F^\eta_{j+\frac{1}{2}} &= \left(H \mathcal{G}^{\eta} + U \mathcal{R}^- \right)  \overline{\eta}_{j} + H \mathcal{G}^G \overline{G}_{j} + H\mathcal{G}^c \nonumber \\
&= F^{\eta, \eta}_{j+\frac{1}{2}} \overline{\eta}_{j} + F^{\eta, G}_{j+\frac{1}{2}} \overline{G}_{j} + F^{\eta, c}_{j+\frac{1}{2}}.
\label{eqn:Fluxfactorsupercritetaright}
\end{align}
While for the flux function of $G$ \eqref{eqn:LineMomeG} the flux approximation  \eqref{eqn:fluxsupercritright} becomes
\begin{align}
F^G_{j+\frac{1}{2}}  &= \left(UH \mathcal{G}^{\eta} + gH \mathcal{R}^- \right)  \overline{\eta}_{j} + \left(U\mathcal{R}^- +  UH \mathcal{G}^G \right) \overline{G}_{j} + UH\mathcal{G}^c \nonumber \\
&= F^{G, \eta}_{j+\frac{1}{2}} \overline{\eta}_{j} + F^{G, G}_{j+\frac{1}{2}} \overline{G}_{j} + F^{G, c}_{j+\frac{1}{2}}.
\label{eqn:FluxfactorsupercritGright}
\end{align}


\subsection{4. Forward Euler Step}
We have obtained the operators for the flux functions for all three flow scenarios, supercrticial flow in the left or right direction and subcritical flow. By substituting the appropriate flux approximation for the physical situation into our update scheme \eqref{eqn:evolupdatescheme} our second-order FEVM can be written as

\begin{align*}
\overline{\eta}_{j}^{\,n + 1} &=  \overline{\eta}^{\,n }_{j} - \frac{\Delta t}{\Delta x}  \left[ \left(\mathcal{F}^{\eta,\eta} \overline{\eta}_j  + \mathcal{F}^{\eta,G} \overline{G}_j + \mathcal{F}^{\eta,c} \right) - \left(\mathcal{F}^{\eta,\eta} \overline{\eta}_{j-1}  + \mathcal{F}^{\eta,G} \overline{G}_{j-1} + \mathcal{F}^{\eta,c} \right)  \right], \\
 \overline{G}^{\,n + 1}_{j} &= \overline{G}^{\,n }_{j} -\frac{\Delta t}{\Delta x}  \left[ \left(  \mathcal{F}^{G,\eta} \overline{\eta}_{j}  + \mathcal{F}^{G,G} \overline{G}_j + \mathcal{F}^{G,c} \right) - \left(  \mathcal{F}^{G,\eta} \overline{\eta}_{j-1}  + \mathcal{F}^{G,G} \overline{G}_{j-1} + \mathcal{F}^{G,c} \right) \right].
\end{align*}

	
Furthermore by noting that the cell averages of quantities that are fourier modes, are fourier modes themselves and making use of \eqref{eqn:fourierfactor} we obtain
	
\begin{align*}
\overline{\eta}_{j}^{\,n + 1} &=  \overline{\eta}^{\,n }_{j} - \frac{\Delta t}{\Delta x}  \left[ \left(1 - e^{-ik\Delta x}\right) \left(\mathcal{F}^{\eta,\eta} \overline{\eta}_j  + \mathcal{F}^{\eta,G} \overline{G}_j \right) \right], \\
\overline{G}^{\,n + 1}_{j} &= \overline{G}^{\,n }_{j} -\frac{\Delta t}{\Delta x}  \left[ \left(1 - e^{-ik\Delta x}\right)\left(  \mathcal{F}^{G,\eta} \overline{\eta}_{j}  + \mathcal{F}^{G,G} \overline{G}_j \right) \right].
\end{align*}


This can be written in matrix form as

\begin{align}
\label{eqn:singleEvolveStep}
\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n+1}_j =& \begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j - \frac{\left(1 - e^{-ik\Delta x}\right) \Delta t}{ \Delta x}\begin{bmatrix}
\mathcal{F}^{\eta,\eta} & \mathcal{F}^{\eta,G} \\\mathcal{F}^{G,\eta} &\mathcal{F}^{G,G} 
\end{bmatrix}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j \nonumber\\=& \left(\matr{I}  - \Delta t \matr{F} \right) \begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j
\end{align}
for a single Euler step. Using this update formula would result in a method that was first-order in time and second-order in space. To increase the order of accuracy in time we use SSP Runge-Kutta time stepping which makes use of multiple Euler steps \eqref{eqn:singleEvolveStep}.

\subsection{5. SSP Runge-Kutta Time Steps}
\label{subsec:RKstepdisp}
The second-order SSP Runge Kutta time stepping uses two forward Euler steps to accomplish a temporally second order accurate method in the following way
\begin{subequations}
	\label{eqn:RKstepfull}
	\begin{align}
	\label{eqn:RKstepfullp1}
	\begin{bmatrix}
	\overline{\eta} \\ \overline{G}
	\end{bmatrix}_j^1 &= \left(\matr{I} - \Delta t\matr{F} \right)\begin{bmatrix}
	\overline{\eta} \\ \overline{G}
	\end{bmatrix}^{n}_j, \\
	\label{eqn:RKstepfullp2}
	\begin{bmatrix}
	\overline{\eta} \\ \overline{G}
	\end{bmatrix}_j^2 &= \left(\matr{I} - \Delta t\matr{F} \right)\begin{bmatrix}
	\overline{\eta} \\ \overline{G}
	\end{bmatrix}_j^1, \\
	\label{eqn:RKstepfullp3}
	\begin{bmatrix}
	\overline{\eta} \\ \overline{G}
	\end{bmatrix}^{n+1}_j &= \frac{1}{2} \left(\begin{bmatrix}
	\overline{\eta} \\ \overline{G}
	\end{bmatrix}^{n}_j + \begin{bmatrix}
	\overline{\eta} \\ \overline{G}
	\end{bmatrix}_j^2\right) .
	\end{align}
\end{subequations}


Substituting \eqref{eqn:RKstepfullp1} and \eqref{eqn:RKstepfullp2} into \eqref{eqn:RKstepfullp3} we can write this in terms of the flux matrix $\matr{F}$ and our cell averages at $t^n$ as
\begin{equation*}
\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n+1}_j = \frac{1}{2} \left(\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j + \left(\matr{I} - \Delta t\matr{F} \right)^2 \begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j\right).
\end{equation*}

Expanding $\left(\matr{I} - \Delta t\matr{F} \right)^2$ we get

\begin{align}
\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n+1}_j &= \left(\matr{I}  -\Delta t\matr{F} + \frac{1}{2}\Delta t^2\matr{F}^2 \right) \begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j \nonumber\\ &=  \matr{E}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j.
\label{eqn:evolutionmatrix}
\end{align}

So we have derived the evolution matrix $\matr{E}$ for the second-order FEVM and have a relationship of the form \eqref{eqn:linearanalaim} as desired. The matrix $\matr{E}$ due to its dependence on the flux matrix $\matr{F}$ will depend on the particular flow scenario determined by the relation between $U$ and $\pm\sqrt{gH}$. However, as these quantities are constants we can analyse all three flow scenarios situations separately. 

Both the convergence and dispersion analysis then proceed by investigating the properties of the evolution matrix $\matr{E}$. We begin with the convergence analysis.

\section{Convergence Analysis}
The linearised Serre equations are linear partial differential equations and therefore we can apply the Lax-equivalence theorem to demonstrate the convergence of our numerical methods by demonstrating their consistency and stability. We provide a Von Neumann stability analysis to demonstrate stability, while providing a demonstration of the consistency assuming our analytic solutions are Fourier modes. This is a weaker version of consistency allowing us to demonstrate it using $\matr{E}$.

\subsection{Stability}
For a numerical method to be stable we must ensure that errors from previous time steps are not amplified by the current time step. To accomplish this we must ensure that
\begin{equation}
\rho\left(\matr{E} \right) \le 1
\label{eqn:stabilitycondition}
\end{equation}
as if $\rho\left(\matr{E} \right) > 1$ then the current time step will amplify the previous time steps errors. Since $\matr{E}$ was derived for our methods by using Fourier modes, this is a Von Neumann stability analysis. 

We calculated $\rho\left(\matr{E} \right)$ numerically for various values of $\Delta x$, $\Delta t$, $k$, $H$ and $U$ to check if \eqref{eqn:stabilitycondition} holds. We summarised our results in Figure~\ref{fig:StabShall} which is a plot of $\rho\left(\matr{E}\right)$ against $\Delta x / \lambda$ for representative values of $k$, $H$ and $U$ where we used g = $9.81m/s^2$ and chose $\Delta t = 0.5 / \left(U + \sqrt{gH}\right) \Delta x$ to satisfy the CFL condition []. This is the common choice of $\Delta t$ in our numerical experiments.

The particular values of $H$ , $k$ and $U$ shown in Figure~\ref{fig:StabShall} where chosen because they represent the behaviour of these plots for all other values we investigated. For these $k$ and $H$ values our shallowness parameter $\sigma = \frac{1}{20}$ and so the Serre equations are applicable []. 

In Figure~\ref{fig:StabShall} it can be seen that all methods have $\rho\left(\matr{E} \right) \le 1$ for $U=0m/s$ and are therefore stable. The two finite difference methods overlap and have $\rho\left(\matr{E} \right) = 1$ for all $\Delta x$ values, while the second-order FDVM and the second-order FEVM also overlap. However, when $U \neq 0m/s$ then $\mathcal{W}$ has $\rho\left(\matr{E} \right) > 1$ for all $\Delta x$ and is therefore unstable. 

The analytic value of $\rho\left(\matr{E}\right)$ is given by using \eqref{eqn:fourierfactor} to write
\begin{equation*}
\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n+1}_j = e^{i \omega \Delta t}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j.
\end{equation*}
Therefore the analytic growth factor is
\begin{align}
\rho\left(\matr{E}\right) = \left| e^{i \omega \Delta t} \right| = \sqrt{\cos^2 \left(\omega \Delta t\right) + \sin^2 \left(\omega \Delta t\right)}  = 1
\end{align}
since $\omega \in \mathbb{R}$. Therefore numerical methods with $\rho\left(\matr{E}\right)$ closer to $1$ are closer to the analytic value. In this sense the two finite difference methods are best, although $\mathcal{W}$ is unstable. While for the FDVM we can see that the higher-order methods better approximate the analytic value, as expected. We can see in Figure~\ref{fig:StabShall} that $\lim_{\Delta x \rightarrow 0}\rho\left(\matr{E}\right) = 1$ for all methods, as expected.

We observed the same results for a wide range of $k$, $H$ and $U$, in particular all methods except $\mathcal{W}$ were stable for any value of these variables. While $\mathcal{W}$ was only stable when $U = 0m/s$.

\begin{figure}
	\centering
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Stabu0khShallz.pdf}\
		\subcaption{$U=0$}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Stabu1khShallz.pdf}
		\subcaption{$U=1$}
	\end{subfigure}
	\caption{Spectral radius of $\matr{E}$ for first-order FDVM ({\color{green!60!black} \solidrule}), second-order FDVM({\color{red} \solidrule}), second-order FEVM ({\color{blue} \solidrule}), third-order FDVM ({\solidrule}), $\mathcal{D}$ ({\color{violet!80!white} \solidrule}) and $\mathcal{W}$ ({\color{orange} \solidrule}). With $H = 1m$ and $k = \frac{\pi}{10}$.}
	\label{fig:StabShall}
\end{figure}




\subsection{Consistency}
For a numerical method to be consistent the error introduced by the method for a single time step must approach zero as the spatial and temporal resolution is increased. We will demonstrate this only for Fourier mode solutions of the linearised Serre equations. Therefore we can demonstrate consistency by investigating the evolution matrix $\matr{E}$. The error introduced for a single time step from $t^n$ to $t^{n+1}$, $\mathcal{T}^n$ is
\begin{equation}
\mathcal{T}^n =  \matr{E}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j -  \begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n+1}_j.
\label{eqn:consistencyTndef}
\end{equation}
To ensure consistency we must have that $ \lim_{\Delta x,\Delta t \rightarrow 0}\left \| \mathcal{T}^n \right \| = 0 $ for all $n$. Taking the norm of both sides of \eqref{eqn:consistencyTndef} we get

\begin{equation}
\left \|\mathcal{T}^n \right \| = \left \|  \matr{E}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j - \begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n+1}_j \right \|.
\label{eqn:consistencyTnnorm1}
\end{equation}
Making use of \eqref{eqn:fourierfactor} in \eqref{eqn:consistencyTnnorm1} we obtain
\begin{equation*}
\left \|\mathcal{T}^n \right \| = \left \|  \matr{E}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j -  e^{i \omega \Delta t} \begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j \right \|.
\end{equation*}
Using the matrix norm induced by the vector norm we have that
\begin{equation}
\left \|\mathcal{T}^n \right \|  \le \left \| \matr{E} -  e^{i \omega \Delta t}\matr{I} \right \| \left \| \begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j\right \|.
\end{equation}
Since $\overline{\eta}^n_j$ and  $\overline{G}^n_j$ are finite and independent of $\Delta x$ and $\Delta t$, if $ \lim_{\Delta x,\Delta t \rightarrow 0}\left \| \matr{E} -  e^{i \omega \Delta t}\matr{I} \right \| = 0 $ then $ \lim_{\Delta x,\Delta t \rightarrow 0}\left \| \mathcal{T}^n \right \| = 0 $ as desired.

We calculated the Taylor series of $\matr{E} -  e^{i \omega_+ \Delta t}\matr{I}$ for all the numerical methods for all flow scenarios. We have reported the lowest order terms of the Taylor series in Tables~\ref{tab:EerrFDVM1}~and~\ref{tab:EerrFDVM1super} for the first-order FDVM, Table~\ref{tab:EerrFDVM2} for the second-order FDVM, Tables~\ref{tab:EerrFDVM3}~and~\ref{tab:EerrFDVM3super} for the third-order FDVM,  Table~\ref{tab:EerrFEVM2} for the second-order FEVM, Table~\ref{tab:EerrD} for $\mathcal{D}$ and Table~\ref{tab:EerrW} for $\mathcal{W}$. To be concise, we only reported the temporal and spatial errors for the supercritical flow scenarios that where different from those when $ -\sqrt{gH} \le U \le \sqrt{gH}$, this only occurred for the spatial errors of the odd order FDVM. 

We observe for all of our methods that the Taylor series of all the elements of $\matr{E} -  e^{i \omega_+ \Delta t}\matr{I}$ have a factor of $\Delta t$. So we have that for all methods 

\begin{align*}
\left \| \matr{E} -  e^{i \omega_+ \Delta t}\matr{I} \right \| &=  \left \| \Delta t \left(\matr{A}_0 +  \begin{bmatrix}
\mathcal{O}\left(\Delta t\right) & \mathcal{O}\left(\Delta t\right)  \\ \mathcal{O}\left(\Delta t\right)&\mathcal{O}\left(\Delta t\right)
\end{bmatrix}\right)\right \|  \nonumber\\ &= |\Delta t|  \left \| \matr{A}_0 +  \begin{bmatrix}
\mathcal{O}\left(\Delta t\right) & \mathcal{O}\left(\Delta t\right)  \\ \mathcal{O}\left(\Delta t\right)&\mathcal{O}\left(\Delta t\right)
\end{bmatrix}\right \|
 \nonumber\\ &\le  |\Delta t| \left(\left \| \matr{A}_0 \right \| + \left \| \begin{bmatrix}
\mathcal{O}\left(\Delta t\right) & \mathcal{O}\left(\Delta t\right)  \\ \mathcal{O}\left(\Delta t\right)&\mathcal{O}\left(\Delta t\right)
\end{bmatrix}\right \|\right).
\end{align*} 

Choosing a particular vector norm such as the $L_1$ or $L_\infty$ and its induced matrix norm we can see from Tables~\ref{tab:EerrFDVM1}-\ref{tab:EerrW} that $\matr{A}$ is independent of $\Delta t$ and finite so that as $\Delta t \rightarrow 0$ we have $|\Delta t| \left(\left \| \matr{A}_0 \right \| + \left \| \begin{bmatrix}
\mathcal{O}\left(\Delta t\right) & \mathcal{O}\left(\Delta t\right)  \\ \mathcal{O}\left(\Delta t\right)&\mathcal{O}\left(\Delta t\right)
\end{bmatrix}\right \|\right)  \rightarrow 0$  and therefore  $\left \| \matr{E} -  e^{i \omega_+ \Delta t}\matr{I} \right \| \rightarrow 0$. Therefore for all our numerical methods we have $ \lim_{\Delta x,\Delta t \rightarrow 0}\left \| \mathcal{T}^n \right \| = 0 $ and so all our numerical methods are consistent for Fourier mode solutions as desired. 

\begin{table}
	\begin{tabular}{l  c c}
		Element & \multicolumn{2}{c}{Lowest Order Term of Error}\\
		&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
		& $\Delta x$&$\Delta t$\\
		\hline && \\
		$E_{00} -  e^{i \omega_+ \Delta t} $& $ - \frac{1}{2} \sqrt{gH} k^2 \Delta t\Delta x$ & $\dfrac{\sqrt{3gH \beta} + 3U}{\beta} ik \Delta t$ \\ & & \\
		$E_{01}$& $ \dfrac{3 + \beta}{4 \beta^2}i k^3\Delta  t\Delta x^2$ &  $ - \frac{3}{\beta} ik\Delta t$ \\ & & \\
		$E_{10}$& $ - \frac{1}{2} \sqrt{gH} k^2 \Delta t\Delta x$ &  $ \left(-gH + \dfrac{3U^2}{\beta}\right)ik \Delta t$ \\ & & \\
		$E_{11} -  e^{i \omega_+ \Delta t}$& $ - \frac{1}{2} \sqrt{gH} k^2 \Delta t\Delta x$ & $\dfrac{\sqrt{3gH \beta} - 3U}{\beta} ik \Delta t$ \\ 
	\end{tabular}
	\caption{Table of the lowest order term of the Taylor series for the elements of $\matr{E} - e^{i \omega_+ \Delta t} \matr{I}$ for the first-order FDVM with $ -\sqrt{gH} \le U \le \sqrt{gH}$ and $\beta = 3 + k^2 H^2$.}
	\label{tab:EerrFDVM1} 
\end{table}

\begin{table}
	\begin{tabular}{l  c  c}
		Scheme &\multicolumn{2}{c}{Lowest Order $\Delta x$ Term of Error}\\
		&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
		& $U < - \sqrt{gH}$&$ \sqrt{gH} < U$\\
		\hline & \\
		$E_{00} -  e^{i \omega_+ \Delta t} $& $ \frac{1}{2} k^2 U \Delta t \Delta x$ &  $- \frac{1}{2} k^2 U \Delta t \Delta x$  \\  &  \\
		$E_{01}$& $\frac{1}{2}gHk^2 \Delta t \Delta x $ & $\frac{1}{2}gHk^2 \Delta t \Delta x $   \\  &  \\
		$E_{11} -  e^{i \omega_+ \Delta t}$& $ \frac{1}{2} k^2 U \Delta t \Delta x$ & $- \frac{1}{2} k^2 U \Delta t \Delta x$   \\  &  \\
	\end{tabular}
	\caption{Table of the lowest order term of the Taylor series for the elements of $\matr{E} - e^{i \omega_+ \Delta t} \matr{I}$ for the first-order FDVM which are different than those in Table~\ref{tab:EerrFDVM1} with $\beta = 3 + k^2 H^2$. }
	\label{tab:EerrFDVM1super} 
\end{table}

\begin{table}
	\begin{tabular}{l  c c}
		Element & \multicolumn{2}{c}{Lowest Order Term of Error}\\
		&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
		& $\Delta x$&$\Delta t$\\
		\hline && \\
		$E_{00} -  e^{i \omega_+ \Delta t} $& $ -\dfrac{i \left(27 + 9H^2k^2 + H^4k^4\right)}{12\beta^2} U k^3 \Delta x^2$ & $\dfrac{\sqrt{3gH \beta} + 3U}{\beta} ik \Delta t$ \\ & & \\
		$E_{01}$& $ \dfrac{3 + \beta}{4 \beta^2}i k^3\Delta  t\Delta x^2$ &  $ - \frac{3}{\beta} ik\Delta t$ \\ & & \\
		$E_{10}$& $ -\left(gH + \dfrac{3U^2}{\beta} + \dfrac{9U^2}{\beta^2}\right)  \dfrac{k^3}{12}\Delta t\Delta x^2$ &  $ \left(-gH + \dfrac{3U^2}{\beta}\right)ik \Delta t$ \\ & & \\
		$E_{11} -  e^{i \omega_+ \Delta t}$& $ \dfrac{-9 + H^2k^2\beta}{\beta^2} \dfrac{k^3}{12} i U \Delta t\Delta x^2$ & $\dfrac{\sqrt{3gH \beta} - 3U}{\beta} ik \Delta t$ \\ 
	\end{tabular}
	\caption{Table of the lowest order term of the Taylor series for the elements of $\matr{E} - e^{i \omega_+ \Delta t} \matr{I}$ for the second-order FDVM with $ -\sqrt{gH} \le U \le \sqrt{gH}$ and $\beta = 3 + k^2 H^2$.}
	\label{tab:EerrFDVM2} 
\end{table}


\begin{table}
	\begin{tabular}{l  c c}
		Element & \multicolumn{2}{c}{Lowest Order Term of Error}\\
		&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
		& $\Delta x$&$\Delta t$\\
		\hline && \\
		$E_{00} -  e^{i \omega_+ \Delta t} $& $ - \frac{1}{12} \sqrt{gH} k^4 \Delta t\Delta x^3$ & $\dfrac{\sqrt{3gH \beta} + 3U}{\beta} ik \Delta t$ \\ & & \\
		$E_{01}$& $ \dfrac{\sqrt{gH}}{4 \beta}i k^5\Delta  t ^2\Delta x^3$ &  $ - \frac{3}{\beta} ik\Delta t$ \\ & & \\
		$E_{10}$& $ - \frac{1}{12} \sqrt{gH} k^4 \Delta t\Delta x^3$ &  $ \left(-gH + \dfrac{3U^2}{\beta}\right)ik \Delta t$ \\ & & \\
		$E_{11} -  e^{i \omega_+ \Delta t}$& $ - \frac{1}{12} \sqrt{gH} k^4 \Delta t\Delta x^3$ & $\dfrac{\sqrt{3gH \beta} - 3U}{\beta} ik \Delta t$ \\ 
	\end{tabular}
	\caption{Table of the lowest order term of the Taylor series for the elements of $\matr{E} - e^{i \omega_+ \Delta t} \matr{I}$ for the third-order FDVM with $ -\sqrt{gH} \le U \le \sqrt{gH}$ and $\beta = 3 + k^2 H^2$.}
	\label{tab:EerrFDVM3} 
\end{table}

\begin{table}
	\begin{tabular}{l  c  c}
		Scheme &\multicolumn{2}{c}{Lowest Order $\Delta x$ Term of Error}\\
		&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
		& $U < - \sqrt{gH}$&$ \sqrt{gH} < U$\\
		\hline & \\
		$E_{00} -  e^{i \omega_+ \Delta t} $& $\frac{1}{12} k^4 U \Delta t \Delta x^3$ &  $ -\frac{1}{12} k^4 U \Delta t \Delta x^3$ \\  &  \\
		$E_{01}$& $\dfrac{1}{4 \beta}iUk^5 \Delta t^2 \Delta x^3 $ & $-\dfrac{1}{4 \beta}iUk^5 \Delta t^2 \Delta x^3 $   \\  &  \\
		$E_{10}$& $\dfrac{1}{12} gHk^4 \Delta t^2 \Delta x^3 $ & $-\dfrac{1}{12} gHk^4 \Delta t^2 \Delta x^3 $  \\  &  \\
		$E_{11} -  e^{i \omega_+ \Delta t}$& $ \frac{1}{12} k^4 U \Delta t \Delta x^3$ & $ -\frac{1}{12} k^4 U \Delta t \Delta x^3$   \\
	\end{tabular}
	\caption{Table of the lowest order term of the Taylor series for the elements of $\matr{E} - e^{i \omega_+ \Delta t} \matr{I}$ for the third-order FDVM which are different than those in Table~\ref{tab:EerrFDVM1} with  $\beta = 3 + k^2 H^2$. }
	\label{tab:EerrFDVM3super} 
\end{table}

\begin{table}
	\begin{tabular}{l  c c}
		Element & \multicolumn{2}{c}{Lowest Order Term of Error}\\
		&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
		& $\Delta x$&$\Delta t$\\
		\hline && \\
		$E_{00} -  e^{i \omega_+ \Delta t} $& $ -\dfrac{i \left(54 + 45H^2k^2 + 10H^4k^4\right)}{120\beta^2} U k^3 \Delta t \Delta x^2$ & $\dfrac{\sqrt{3gH \beta} + 3U}{\beta} ik \Delta t$ \\ & & \\
		$E_{01}$& $ \dfrac{\beta - 3}{\beta^2} \dfrac{ik^3}{40} \Delta  t\Delta x^2$ &  $ - \frac{3}{\beta} ik\Delta t$ \\ & & \\
		$E_{10}$& $ -\left(gH - \dfrac{15U^2}{\beta} + \dfrac{9U^2}{\beta}\right)  \dfrac{k^3}{120}\Delta t\Delta x^2$ &  $ \left(-gH + \dfrac{3U^2}{\beta}\right)ik \Delta t$ \\ & & \\
		$E_{11} -  e^{i \omega_+ \Delta t}$& $ \dfrac{126 + 75H^2 k^2 + 10 H^4 k^4}{\beta^2} \dfrac{k^3}{120} i U \Delta t\Delta x^2$ & $\dfrac{\sqrt{3gH \beta} - 3U}{\beta} ik \Delta t$ \\ 
	\end{tabular}
	\caption{Table of the lowest order term of the Taylor series for the elements of $\matr{E} - e^{i \omega_+ \Delta t} \matr{I}$ for the second-order FEVM with $ -\sqrt{gH} \le U \le \sqrt{gH}$ and $\beta = 3 + k^2 H^2$.}
	\label{tab:EerrFEVM2} 
\end{table}

\begin{table}
	\begin{tabular}{l  c c}
		Element & \multicolumn{2}{c}{Lowest Order Term of Error}\\
		&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
		& $\Delta x$&$\Delta t$\\
		\hline && \\
		$E_{00} -  e^{i \omega_+ \Delta t} $&  $\dfrac{ik^3}{3} U \Delta t \Delta x^2$ & $ \sqrt{\dfrac{3gH}{\beta}} 2ik \Delta t $ \\ & & \\
		$E_{01}$& $\dfrac{iHk^3}{3} \Delta t \Delta x^2$ &  $-2Hi k \Delta t$ \\ & & \\
		$E_{10}$& $ \dfrac{ig \left(3 + \beta\right)}{2\beta^2} k^3\Delta t \Delta x^2$ &  $ -\dfrac{6igk}{\beta} \Delta t$ \\ & & \\
		$E_{11} -  e^{i \omega_+ \Delta t}$& $\dfrac{ik^3}{3} U \Delta t \Delta x^2$ & $ \sqrt{\dfrac{3gH}{\beta}} 2ik \Delta t $ \\ 
	\end{tabular}
	\caption{Table of the lowest order term of the Taylor series for the elements of $\matr{E} - e^{i \omega \Delta t} \matr{I}$ for $\mathcal{D}$ with $\beta = 3 + k^2 H^2$.}
	\label{tab:EerrD} 
\end{table}

\begin{table}
	\begin{tabular}{l  c c}
		Element & \multicolumn{2}{c}{Lowest Order Term of Error}\\
		&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
		& $\Delta x$&$\Delta t$\\
		\hline && \\
		$E_{00} -  e^{i \omega_+ \Delta t} $&  $\dfrac{ik^3}{6} U \Delta t \Delta x^2$ & $ \sqrt{\dfrac{3gH}{\beta}} ik \Delta t $ \\ & & \\
		$E_{01}$& $\dfrac{iHk^3}{6} \Delta t \Delta x^2$ &  $-Hi k \Delta t$ \\ & & \\
		$E_{10}$& $ \dfrac{ig \left(3 + \beta\right)}{2\beta^2} k^3\Delta t \Delta x^2$ &  $ -\dfrac{6igk}{\beta} \Delta t$ \\ & & \\
		$E_{11} -  e^{i \omega_+ \Delta t}$& $\dfrac{ik^3}{3} U \Delta t \Delta x^2$ & $ \sqrt{\dfrac{3gH}{\beta}} 2ik \Delta t $ \\ 
	\end{tabular}
	\caption{Table of the lowest order term of the Taylor series for the elements of $\matr{E} - e^{i \omega_+ \Delta t} \matr{I}$ for $\mathcal{W}$ with $\beta = 3 + k^2 H^2$.}
	\label{tab:EerrW} 
\end{table}




\section{Dispersion Analysis}
To study the dispersion of our numerical methods we must calculate $\omega$ for our numerical methods. Making use of \eqref{eqn:fourierfactor} in \eqref{eqn:evolutionmatrix} we get 
\begin{equation}
e^{i \omega \Delta t}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j =  \matr{E}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j.
\label{eqn:dispanalomeganum1}
\end{equation}
Assuming that $\matr{E}$ has an eigenvalue decomposition $\matr{E} = \matr{P}^{-1} \matr{\Lambda} \matr{P}$ and substituting it into \eqref{eqn:dispanalomeganum1} we get
\begin{equation}
e^{i \omega \Delta t}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j =  \matr{P}^{-1} \matr{\Lambda} \matr{P}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j.
\label{eqn:dispanalomeganum2}
\end{equation}
Left multiplying \eqref{eqn:dispanalomeganum2} by $\matr{P}$ we obtain
\begin{equation}
e^{i \omega \Delta t} \matr{P}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j =   \matr{\Lambda} \matr{P}\begin{bmatrix}
\overline{\eta} \\ \overline{G}
\end{bmatrix}^{n}_j.
\label{eqn:dispanalomeganum3}
\end{equation}
Since $\Lambda$ is a diagonal matrix we must have that $e^{i \omega_+ \Delta t} = \lambda_+$ and $e^{i \omega_- \Delta t} = \lambda_-$ where $\lambda_\pm$ are the eigenvalues of $\matr{E}$ and $\omega_\pm$ are the positive and negative branches of the dispersion relation. Therefore the dispersion relation of a numerical method is
\begin{equation}
\widetilde{\omega}_\pm = \frac{1}{i \Delta t} \log\left[ \lambda_\pm\right].
\end{equation}
By comparing $\widetilde{\omega}_\pm$ with the analytic $\omega_\pm$ given by the linearised Serre equations we can determine the error in the dispersion relation for the numerical method. The real part of $\widetilde{\omega}_\pm$ determines the speed of a wave, while the imaginary part determines the change in amplitude. For $\omega_\pm$ the imaginary part is zero and so the amplitude of waves of the linearised Serre equations are constant in time.

The relative error in the dispersion relation was plotted against $\Delta x / \lambda$ for representative values of $H$, $U$ and $k$.  We used $g = 9.81m/s^2$ and chose $\Delta t = 0.5 / \left(U + \sqrt{gH}\right) \Delta x$ to satisfy the CFL condition [].

In Figures~\ref{fig:Dispu0Shall}~and~\ref{fig:Dispu1Shall} we present the plots for $kH = \pi / 10$ so that $\sigma = 1 / 20$ and therefore the water is shallow so the Serre equations are appropriate. We present the real and imaginary errors separately as they account for different physical phenomenon and also present the total relative error as a measure of the overall difference of behaviour between waves in the numerical method and the waves of the linearised Serre equations.

From Figures~\ref{fig:Dispu0Shall}~and~\ref{fig:Dispu1Shall} we can see that all methods approximate the dispersion relation of the Serre equations well with the approximation becoming better as $\Delta x \rightarrow 0$, as expected.

For the real part of the dispersion error the FEVM and the FDVM outperform the two finite difference methods and therefore will better approximate the speed of waves of the linearised Serre equations.  However, for the dilation of waves the roles are reversed with the two finite difference methods either dilating the waves very little ($\mathcal{W}$ for $U>0$) or not at all. When taking both effects into account with the complete error we see that the first-order FDVM has the largest dispersion error followed by $\mathcal{W}$, $\mathcal{D}$, the second-order FEVM, the second-order FDVM and finally the third-order FDVM has the lowest dispersion error. So that the total dispersion error appears to be mainly driven by the order of accuracy of the numerical scheme. These results justify choosing these FDVM over these finite difference methods for the Serre equations. 

Figures~\ref{fig:Dispu0Shall}~and~\ref{fig:Dispu1Shall} furthermore demonstrate that the second-order FDVM is superior to the FEVM not just for the complete dispersion error, but its real and imaginary parts individually as well. Therefore the second-order FDVM will do a better job in accurately modelling the speed and amplitude of waves than the second-order FEVM. Interestingly, for the two finite difference methods and the first-order FDVM there seems to be some trade-off between predicting the speed or amplitude of the waves very well. 

We observed similar results across a wide array of $k$, $H$ and $U$ values. However, as $kH$ is increased the distinction between the second-order FDVM and the second-order FEVM becomes less pronounced. This can be seen in Figure~\ref{fig:Dispu0Fill} where $kH = 2.5$ and $\sigma = 5/4 \pi > 1/20$ so that the water is no longer shallow.

These $kH$ values are the same as those in the literature \cite{Filippini-etal-2016-381}, and our results are similar for the real part of the dispersion error. Our FDVM and the FEVM compare favourably with the methods described and analysed in \cite{Filippini-etal-2016-381}. Furthermore, we extended the work of \cite{Filippini-etal-2016-381} by allowing for non-zero values of $U$ and examining the imaginary and complete error in the dispersion relation. 

Figure~\ref{fig:Dispu1Fill} demonstrates that the results of the real part of the dispersion error  is slightly different if we allow for non-zero values of $U$. In particular the non-zero value of $U$ changes the real part of the dispersion error for the first-order FDVM, most significantly when $kH = 2.5$. Therefore for some methods allowing for non-zero values of $U$ can have a significant impact on the conclusions drawn from the dispersion analysis. Furthermore taking the imaginary part of the dispersion error into account is important as $\omega$ determines not only the speed of waves but also their amplitude. In particular it is possible that a method like the first-order FDVM performs very well for the real part of the dispersion error and poorly for the imaginary part, leading to false conclusions about the accuracy of the method.


\begin{figure}
	\centering
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu0khShallRez.pdf}
		\subcaption{Real part}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu0khShallImz.pdf}
		\subcaption{Imaginary part}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu0khShallz.pdf}
		\subcaption{Complete}
	\end{subfigure}
	\caption{Relative dispersion error for first-order FDVM ({\color{green!60!black} \solidrule}), second-order FDVM({\color{red} \solidrule}), second-order FEVM ({\color{blue} \solidrule}), third-order FDVM ({\solidrule}), $\mathcal{D}$ ({\color{violet!80!white} \solidrule}) and $\mathcal{W}$ ({\color{orange} \solidrule}). With $H = 1m$  and $k = \frac{\pi}{10}$ and $U = 0 m/s$.}
	\label{fig:Dispu0Shall}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu1khShallRez.pdf}
		\subcaption{Real part}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu1khShallImz.pdf}
		\subcaption{Imaginary part}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu1khShallz.pdf}
		\subcaption{Complete}
	\end{subfigure}
	\caption{Relative dispersion error for first-order FDVM ({\color{green!60!black} \solidrule}), second-order FDVM({\color{red} \solidrule}), second-order FEVM ({\color{blue} \solidrule}), third-order FDVM ({\solidrule}), $\mathcal{D}$ ({\color{violet!80!white} \solidrule}) and $\mathcal{W}$ ({\color{orange} \solidrule}). With $H = 1m$  and $k = \frac{\pi}{10}$ and $U = 1 m/s$.}
	\label{fig:Dispu1Shall}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu0khFillRez.pdf}
		\subcaption{Real part}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu0khFillImz.pdf}
		\subcaption{Imaginary part}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu0khFillz.pdf}
		\subcaption{Complete}
	\end{subfigure}
	\caption{Relative dispersion error for first-order FDVM ({\color{green!60!black} \solidrule}), second-order FDVM({\color{red} \solidrule}), second-order FEVM ({\color{blue} \solidrule}), third-order FDVM ({\solidrule}), $\mathcal{D}$ ({\color{violet!80!white} \solidrule}) and $\mathcal{W}$ ({\color{orange} \solidrule}). With $H = 1m$  and $k = 2.5$ and $U = 0m/s$.}
	\label{fig:Dispu0Fill}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu1khFillRez.pdf}
		\subcaption{Real part}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu1khFillImz.pdf}
		\subcaption{Imaginary part}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp4/figures/Dispu1khFillz.pdf}
		\subcaption{Complete}
	\end{subfigure}
	\caption{Relative dispersion error for first-order FDVM ({\color{green!60!black} \solidrule}), second-order FDVM({\color{red} \solidrule}), second-order FEVM ({\color{blue} \solidrule}), third-order FDVM ({\solidrule}), $\mathcal{D}$ ({\color{violet!80!white} \solidrule}) and $\mathcal{W}$ ({\color{orange} \solidrule}). With $H = 1m$  and $k = 2.5$ and $U = 1m/s$.}
	\label{fig:Dispu1Fill}
\end{figure}


The Taylor series expansion of $\widetilde{\omega}$ was also derived for all the numerical methods. We have compiled the lowest order terms of the Taylor series for $\widetilde{\omega}_+~-~\omega_+$ in Table \ref{tab:Wfactor} when $ -\sqrt{gH} \le U \le \sqrt{gH}$ for the FDVM and FEVM. In Table \ref{tab:Wfactor} it is clear that these schemes estimated $\omega$ with the expected order of accuracy in both space and time.

We also present the lowest order terms of the Taylor series for $\widetilde{\omega}_+~-~\omega_+$ for both $ U < -\sqrt{gH}$ and $ U > \sqrt{gH}$ in Table~\ref{tab:Wspatfactor}. We only present the errors that are different from those reported in Table~\ref{tab:Wfactor}, this was only the case for the spatial error of the odd-order numerical methods. We can see that for all the flow scenarios that our FDVM and the FEVM have the correct order of accuracy when approximating $\omega_+$. 

Finally we present the lowest order terms of the Taylor series for $\widetilde{\omega}_+~-~\omega_+$ for the finite difference methods in Table~\ref{tab:WFDspatfactor}. These methods do not change depending on the value of the physical quantities. The two finite difference methods both have the correct order of accuracy in both space and time.  

Because all methods were demonstrated to have the expected order of accuracy in approximating $\omega_+$ this implies that for small $\Delta x$ values the order of accuracy will be the primary driver of the dispersion error. The results for $\omega_-$ are very similar and in particular have the same order of accuracy in both space and time for all methods. 

	\begin{table}
		\begin{tabular}{l  c  c}
			Scheme & \multicolumn{2}{c}{Lowest Order Term of Error}\\
			&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
			& $\Delta x$&$\Delta t$\\
			\hline && \\
			$\text{FDVM}_1$& $-\left(2 \sqrt{gH} - \sqrt{\dfrac{3U}{\beta }}\right)  \dfrac{ik^2}{4} \Delta x$ & $\dfrac{i \omega_+^2}{2} \Delta t$ \\ & & \\
			$\text{FDVM}_2$& $\dfrac{2\beta U -3 \sqrt{3 gH \beta}}{\beta^2}  \dfrac{k^3}{24}\Delta x ^2$ & $- \dfrac{\omega^3_+}{6 }  \Delta t^2$ \\ & & \\
			$\text{FEVM}_2$& $\left(U   + \dfrac{\left(42 + 15 k^2H^2\right) \sqrt{3gH \beta}}{20\beta^2}  \right) \dfrac{k^3}{12 } \Delta x^2$ &  $- \dfrac{\omega^3_+}{6 }  \Delta t^2$  \\ & & \\
			$\text{FDVM}_3$& $-\left({2\sqrt{gH} - \sqrt{3\beta}U }\right) \dfrac{ik^4}{24} \Delta x^3$ & $-\dfrac{i\omega^4_+}{24 } \Delta t^3$ \\ 
		\end{tabular}
		\caption{Table showing lowest order error term for approximating $\omega_+$ for all FDVM and the FEVM. With $ -\sqrt{gH} \le U \le \sqrt{gH}$ and $\beta = 3 + H^2 k^2 $. }
		\label{tab:Wfactor} 
	\end{table}

	\begin{table}
		\begin{tabular}{l  c  c}
			Scheme &\multicolumn{2}{c}{Lowest Order $\Delta x$ Term of Error}\\
				&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
				& $U < - \sqrt{gH}$&$ \sqrt{gH} < U$\\
			\hline & \\
			$\text{FDVM}_1$& $-\left(2U + \sqrt{\dfrac{3gH}{\beta}}\right)  \dfrac{ik^2}{4} \Delta x$ &  $\left(2U + \sqrt{\dfrac{3gH}{\beta}}\right)  \dfrac{ik^2}{4} \Delta x$  \\  &  \\
			$\text{FDVM}_3$& $-\left(2U + \sqrt{\dfrac{3gH}{\beta}} \right) \dfrac{ik^4}{24} \Delta x^3$ & $\left(2U + \sqrt{\dfrac{3gH}{\beta}} \right) \dfrac{ik^4}{24} \Delta x^3$   \\  &  \\
		\end{tabular}
		\caption{Table showing different lowest order spatial error term for approximating $\omega_+$ for all FDVM and the FEVM for different values of $U$. With $\beta = 3 + H^2 k^2 $. }
		\label{tab:Wspatfactor} 
	\end{table}
	
		\begin{table}
		\begin{tabular}{l  c  c}
			Scheme & \multicolumn{2}{c}{Lowest Order Term of Error}\\
			&  \multicolumn{2}{l}{\rule{0.7\textwidth}{0.4pt}} \\
			& $\Delta x$&$\Delta t$\\
			\hline && \\
			$\mathcal{D}$& $- \left(U + \dfrac{\left( 4 + H^2k^2\right)\sqrt{3gH\beta}}{4 \beta^2}\right)\dfrac{k^3}{3 }\Delta x^2$  &$ -\dfrac{\omega_+^3}{3}\Delta t^2$ \\ & & \\
			$\mathcal{W}$& $\left(U + \dfrac{\left( 4 + H^2k^2\right)\sqrt{3gH\beta}}{4 \beta^2}\right)\dfrac{k^3}{3 }\Delta x^2$  &$ \Bigg( \beta U^2\left[9\sqrt{3gH \beta} + 4 \beta U\right]  $  \\ & & $+ 3gH^2\left[\sqrt{3gH \beta} + 6 \beta U\right] \Bigg) \dfrac{k^3}{18 \beta^2}\Delta t^2$
		\end{tabular}
			\caption{Table showing lowest order error term for approximating $\omega_+$ for $\mathcal{D}$ and $\mathcal{W}$. }
			\label{tab:WFDspatfactor} 
		\end{table}

 %W x orig :  \dfrac{gH\left( 4 + H^2k^2\right)}{2 \beta \sqrt{3gH\beta}}
