
\chapter{Linear Analysis of Numerical Methods}
\label{chp:AnalNumMethod}
The most important property of a numerical method is convergence, because convergence guarantees that as we increase the spatial and temporal resolution of a numerical method, the numerical methods solutions better approximate the solutions of the differential equations they are attempting to approximate. This is precisely the desired property for a given numerical method. For linear partial differential equations the Lax-equivalence theorem states that a numerical method is convergent if and only if it is stable and consistent \cite{Lax-Richtmyer-1956-267}. Where consistency means that the error introduced by the numerical method at every time step approaches zero as the spatial and temporal resolution is increased. While stability means that the errors from all previous time steps are not amplified by the current time step.

The convergence of the finite difference volume methods and the finite element volume methods are inherited from the convergence of the finite volume methods at their core [][?]. The convergence of the finite difference methods introduced in Chapter [] has not been shown for the Serre equations and so we investigate it here. The consistency of the finite difference methods is very straightforward, given that we are using well tested approximations and so we instead focus on demonstrating stability for these methods. In particular we performed a Von Neumann stability \cite{Charney-etal-1950-237} analysis on both finite difference methods applied to the linearised Serre equations. We found that the naive second-order finite difference was stable under the CFL condition for all flow scenarios while the Lax-Wendroff method was only stable under the CFL condition when there was no background mean flow ($U=0$).

Demonstrating convergence of a particular method only provides a guarantee that as the spatial and temporal resolution is increased the numerical solutions approach the true solutions. However, the speed of this convergence is also an important property of the numerical method as it determines how fast you can obtain a solution with a given accuracy. This is typically measured using the order of accuracy. We investigate the order of accuracy of our methods in Chapter [] using both analytical and forced solutions. 

Furthermore partial differential equations can possess more specialised properties that are desirable for the numerical methods as well. For physical systems the solutions of the partial differential equations typically conserve some known quantities. In particular the solutions of the Serre equations conserve mass $h$, momentum $uh$, height multiplied by the irrotationality $G$ \cite{Carter-Cienfuegos-2011-259} and the Hamiltonian $\mathcal{H}$. Since the true solutions conserve these quantities it is desirable for our numerical solutions to conserve them as well. The conservation properties of our FDVM and FEVM is investigated in Chapter [] using numerical solutions.

Another property of the Serre equations is that it possesses a dispersion relation that well approximates the dispersion relation for the Euler equations. Since the dispersion relation determines the speed of propagation for waves, approximating it well is of particular interest for tsunami modelling. For this reason we wish to know the error in the dispersion relation for all the numerical methods we are interested in; the finite difference volume methods and the finite element volume methods. In this chapter we perform an analysis of the dispersion relation for all numerical methods applied to the linearised Serre equations to study the dispersion error. 

This chapter will present the Von Neumann stability and the dispersion relation analysis of our numerical methods. We group these two analyses together as they employ very similar methods and both use the linearised Serre equations. We shall leave the rest of the analyses of the numerical methods in this thesis to Chapters [] where we investigate them using their numerical solutions.

Both the dispersion relation and stability analysis are performed on the linearised Serre equation with horizontal beds. We neglect bed terms because our finite difference methods neglect them and because variations in the bed have no effect on the dispersion relation. We perform our analysis of the linearised Serre equations firstly because it is the equations from which the dispersion relation is derived and secondly because it serves as a first step towards demonstrating the stability of these methods for the full nonlinear Serre equations, which is outside the scope of this thesis. 
 
\subsection{Linearised Serre equations with horizontal bed}
The Serre equations with a horizontal bed were given earlier \eqref{eqn:FullSerreNonConHorizbed} and we present them here to remind the reader
\begin{equation*}
\frac{\partial h}{\partial t} + \dfrac{\partial (uh)}{\partial x} = 0
\end{equation*}
and
\begin{equation*}
\dfrac{\partial (uh)}{\partial t} + \dfrac{\partial}{\partial x} \left ( u^2h + \dfrac{gh^2}{2} + \dfrac{h^3}{3}{ \Phi }  \right ) = 0.
\end{equation*}

To linearise these equations we assume that we are modelling waves which are perturbations ontop of a flow with a mean height $H$ and a mean flow velocity $U$ so that

\begin{align}
\label{eq:pertubation}
h(x,t) &= H + \delta \eta(x,t) + \mathcal{O}\left(\delta^2 \right), \\
u(x,t) &= U + \delta \upsilon(x,t) + \mathcal{O}\left(\delta^2 \right).
\end{align}
Where $\delta \ll 1$, so that we are modelling relatively small waves where terms of order $\delta^2$ are negligible. We substitute this into the Serre equations and neglect terms of order $\delta^2$ to obtain the linearised Serre equations with horizontal beds

\begin{subequations}
	\begin{gather}
		\label{eqn:LinCont}
		\frac{\partial  \eta}{\partial  t} + H\frac{\partial  \upsilon}{\partial  x} + U\frac{\partial  \eta}{\partial  x} +  = 0
	\end{gather}
	and
	\begin{gather}
	\label{eqn:LineMome}
	H\frac{\partial  \upsilon}{\partial  t} + gH\frac{\partial  \eta}{\partial  x} + UH\frac{\partial  \upsilon}{\partial  x} - \frac{H^3}{3}\left(U\frac{\partial^3  \upsilon}{\partial  x^3} + \frac{\partial^3  \upsilon}{\partial  x^3 \partial  t}  \right)  = 0.
	\end{gather}
\label{eqn:LinSerre}	
Where the linearised equation for $G$ is
\begin{gather}
	G = U\left(H + \eta\right) + H\upsilon -\frac{H^3}{3} \frac{\partial^2 \upsilon}{\partial x^2}.
	\label{eqn:LinConSerreG}
\end{gather}	
\end{subequations}

%Phillipine stuff in here%
\section{Dispersion Error}
To study the error in the dispersion relation caused by the numerical methods we will follow the work of \cite{Filippini-etal-2016-381} who used a range of numerical methods on a different reformulation of the Serre equations. We will demonstrate this analysis for one example the second order FDVM to show the process and then only present the results at the end for the other FDVM. Additionally we will also go through the process for the finite element part of the second-order FEVM. At the end we will present all the values we obtained and compare the dispersion error of all the methods.

We begin by assuming that $U = 0$, so that there is no mean flow velocity as in \cite{Filippini-etal-2016-381}. This is a reasonable simplification because for most ocean wave applications we are interested in modelling waves on quiescent water, such as tsunamis. Additionally the difficult term to approximate in the dispersion relation is the term which determines the speed of waves on still water, and not the contribution from $U$.

By assuming that $U= 0$ the equations \eqref{eqn:LinSerre} and \eqref{eqn:LinConSerreG} reduce to

\begin{subequations}
	\label{eqn:LinSerreu0}
	\begin{gather}
	\label{eqn:LinContu0}
	\frac{\partial  \eta}{\partial  t} + H\frac{\partial  \upsilon}{\partial  x} = 0
	\end{gather}
	and
	\begin{gather}
	\label{eqn:LineMomeu0}
	H\frac{\partial  \upsilon}{\partial  t} + g H \frac{\partial  \eta}{\partial  x} - \frac{H^3}{3}\left(\frac{\partial^3  \upsilon}{\partial  x^3 \partial  t}  \right)  = 0
	\end{gather}	
with
	\begin{gather}
	G = H\upsilon -\frac{H^3}{3} \frac{\partial^2 \upsilon}{\partial x^2}.
	\label{eqn:LinConSerreGu0}
	\end{gather}	
\end{subequations}

The linearised equations \eqref{eqn:LinSerreu0} can be reformulated into equations with $\eta$ and $G$ as conserved variables as in the nonlinear case to obtain
\begin{subequations}
	\begin{gather}
	\label{eqn:LinContG}
	\frac{\partial  \eta}{\partial  t} + H\frac{\partial  \upsilon}{\partial  x} = 0
	\end{gather}
	and
	\begin{gather}
	\label{eqn:LineMomeG}
	\frac{\partial  G}{\partial  t} + g H \frac{\partial  \eta}{\partial  x}  = 0.
	\end{gather}
	\label{eqn:LinSerreG}	
\end{subequations}
These will be the equations we will apply our numerical methods to in order to assess their dispersion error. It can be seen that these equations are linear conservation equations for $\eta$ and $G$, and so our FDVM and FEVM methods are applicable to them.

The final assumption of this analysis is that $\eta$ and $\upsilon$ are periodic functions in both space and time. In particular we assume that these quantities are Fourier modes, which for a general quantity $q$ is given by
\begin{equation}
q(x,t) = q(0,0) e^{i\left(\omega t + kx\right)}.
\label{eqn:FourierNode}
\end{equation}
This is precisely the assumption made to derive the dispersion relation of the linearised Serre equations. A consequence of these quantities being Fourier modes and our use of fixed temporal and spatial grids is that
\begin{align}
q^{n}_{j \pm l} = q^n_j e^{\pm ik l\Delta x} & & \text{and} & & q^{n \pm l}_{j} = q^n_j e^{\pm i \omega l\Delta t}.
\label{eqn:fourierfactor}
\end{align}



\subsection{Overview of the analysis}
We will now present a brief overview of how this analysis progresses for a single evolution step of a FDVM. We provide a sketch of this process at the outset so that our example is more illuminating. The dispersion analysis also extends to the Runge-Kutta steps which uses multiple evolution steps to increase the temporal order of accuracy. How these multiple evolution steps interact to determine the dispersion relation will be demonstrated in subsection \ref{subsec:RKstepdisp}.

For the FDVM the evolution step progresses like so
\begin{enumerate}
	\item We possess the vectors of the cell averages $\bar{\vecn{\eta}}$ and $\bar{\vecn{G}}$ at the current time
	\item We use the inverse of the map $\mathcal{M}$ between cell averages and nodal values to calculate ${\vecn{\eta}}$ and ${\vecn{G}}$ from $\bar{\vecn{\eta}}$ and $\bar{\vecn{G}}$ where
	\begin{align*}
	&{\vecn{\eta}} = \mathcal{M}^{-1}\left(\bar{\vecn{\eta}} \right), 
	&{\vecn{G}} = \mathcal{M}^{-1}\left(\bar{\vecn{G}} \right). 
	\end{align*}
	\item We use the inverse of the map $\mathcal{G}$ given by the elliptic equation  between $G$ and $\upsilon$ to calculate ${\vecn{\upsilon}}$ from ${\vecn{G}}$ and $H$
	\[{\vecn{\upsilon}} = \mathcal{G}^{-1}\left(H, {\vecn{G}}\right)\]
	\item We reconstruct $\eta$ and $G$ at $x^-_{j+1/2}$ and $x^+_{j+1/2}$ from the cell average values using $\mathcal{R}^{-}$ and $\mathcal{R}^{+}$ while reconstructing $\upsilon$ at $x_{j+1/2}$ from the nodal values using $\mathcal{R}^{\upsilon}$ for all cell edges. So that
	\begin{align*}
	&\eta^-_{j+1/2} = \mathcal{R}^{-}\left(\bar{\vecn{\eta}}\right),  &G^-_{j+1/2} = \mathcal{R}^{-}\left(\bar{\vecn{G}}\right), \\
	&\eta^+_{j+1/2} = \mathcal{R}^{+}\left(\bar{\vecn{\eta}}\right),  &G^+_{j+1/2} = \mathcal{R}^{+}\left(\bar{\vecn{G}}\right), \\
	&\upsilon_{j+1/2} = \mathcal{R}^{\upsilon}\left({\vecn{\upsilon}}\right).
	\end{align*}
	\item We calculate $F_{j+1/2}$ using $\mathcal{F}$ for each j
	\[F_{j+1/2} =\mathcal{F} \left(\eta^-_{j+1/2}, G^-_{j+1/2},\eta^+_{j+1/2}, G^+_{j+1/2},\upsilon_{j+1/2}  \right). \]
	\item We use update formula \eqref{eqn:evolupdatescheme} to evolve the vectors $\bar{\vecn{\eta}}$ and $\bar{\vecn{G}}$ from the current time to the next time.
\end{enumerate}

This analysis uses the fact that $\upsilon$, $\eta$ and $G$ are Fourier modes and so we have relations between our quantities at different grid points \eqref{eqn:fourierfactor}. Together with the fact that these operators are just linear combinations of the quantities at different grid points to derive these operators as simple multipliers that are independent of the particular time step and grid point.
For example we have in the case of the elliptic operator this process leads to
\[G_j = \mathcal{G} \times u_j.\]
Where $\mathcal{G}$ is independent of $j$ and $n$.

This can be done for all the operators given above. So that finally these operators are combined to give the matrix $\matr{F}$ that calculates the flux at the current time allowing us to write the update formula \eqref{eqn:evolupdatescheme} as

\begin{equation*}
\begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n+1}_j = \left(\matr{I}  - \Delta t \matr{F} \right) \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j
\end{equation*}
in terms of primitive variables. From this equation the dispersion relation of the method can be calculated for a single evolution step.

We will now present an example of this analysis for the second-order FDVM and FEVM. Although both methods are very similar, we present the FEVM as well as the FDVM because the finite element method has some significant details that will be addressed. In this analysis we break the evolution step up into three parts; the elliptic equation which relates $G$ to $\upsilon$, the evolution equation we use to update $\eta$ and $G$ and the Runge-Kutta steps we use to increase the order of accuracy of the method in time. We begin with the elliptic equation.

\subsection{Elliptic Equation}
For both the finite difference and the finite element method we are trying to determine the coefficient $\mathcal{G}$ from the elliptic equation for the linearised Serre equation with $U=0$ \eqref{eqn:LinConSerreGu0} such that
\[G_j = \mathcal{G}\upsilon_j.\]
We will use subscripts to denote the method that generates a particular coefficient. For this analysis we will demonstrate how $\mathcal{G}_{FD2}$ and $\mathcal{G}_{FEM2}$ are generated by the finite difference method and the finite element method respectively. At the end we will also give $\mathcal{G}_{FD4}$ from the fourth order finite difference method and $\mathcal{G}_A$ which is the analytic value. We begin with the second-order finite difference method.
\subsubsection{Finite Difference ($\mathcal{G}_{FD2}$)}
The elliptic equation at a particular grid point $x_j$ is
\[G_j = H\upsilon_j -\frac{H^3}{3} \left(\frac{\partial^2 \upsilon}{\partial x^2}\right)_j.\]
For the second-order finite difference method the derivative $\frac{\partial^2 \upsilon}{\partial x^2}$ is approximated by   
\[ \left(\frac{\partial^2 \upsilon}{\partial x^2}\right)_j = \frac{\upsilon_{j-1} - 2\upsilon_{j} + \upsilon_{j+1}}{\Delta x^2}.\]
Making use of \eqref{eqn:fourierfactor} this becomes
\[ \left(\frac{\partial^2 \upsilon}{\partial x^2}\right)_j = \frac{\upsilon_{j} e^{-ik\Delta x} - 2\upsilon_{j} + \upsilon_{j}e^{ik\Delta x}}{\Delta x^2}.\]
Which reduces to
\[ \left(\frac{\partial^2 \upsilon}{\partial x^2}\right)_j = \frac{ 2\cos\left(k\Delta x\right) - 2 }{\Delta x^2} \upsilon_{j}.\]
Substituting this approximation into our elliptic equation one obtains
\[G_j = \left(H -\frac{H^3}{3} \frac{ 2\cos\left(k\Delta x\right) - 2 }{\Delta x^2}\right) \upsilon_{j}.\] 
Therefore we have an equation which is independent of $j$ which gives the second order finite difference's approximation to $\mathcal{G}_A$ as desired. 

In particular for the centred second-order finite difference method we have
\[\mathcal{G}_{FD2} = \left(H -\frac{H^3}{3} \frac{ 2\cos\left(k\Delta x\right) - 2 }{\Delta x^2}\right).\]
The process to calculate $\mathcal{G}_{FD4}$ is very similar and so we omit it for brevity.
\subsubsection{Finite Element Method} 
Since finite difference methods are very similar it is sufficient to give only one example. The finite element method is slightly different and so we also present the working for it here. As with the finite difference method we desire a coefficient independent of $j$, which we call $\mathcal{G}_{FEM2}$. However, unlike the finite difference case this does not come from an equation relating $G_j$ and $u_j$, but instead an equation between $G_j$ and $u_{j+1/2}$. This is because our finite element method calculates $u_{j+1/2}$ directly, and we use this value without a reconstruction in the flux calculation.

To attain this equation we being with the matrix equation of the FEM for the linearised equations \eqref{eqn:LinConSerreGu0}

\begin{multline*}
\sum_j \frac{\Delta x}{6}\begin{bmatrix} G^+_{j -1/2} \\2 G^+_{j -1/2}+2 G^-_{j +1/2} \\ G^-_{j +1/2} \end{bmatrix} = \\\sum_j \left(H\frac{\Delta x}{30}\begin{bmatrix} 4 &2 &-1 \\2 &16 &2  \\-1 &2 &4 \end{bmatrix} + \frac{H^3 }{9\Delta x}\begin{bmatrix} 7 &-8 &1  \\-8 &16 &-8  \\1 &-8 &7  \end{bmatrix} \right) \begin{bmatrix} \upsilon_{j -1/2} \\\upsilon_{j} \\ \upsilon_{j +1/2} \end{bmatrix}.
\end{multline*}
Because we have demonstrated how to calculate this matrix equation for the full nonlinear Serre equations we omit the working here.

%minmod limiter for G
 Using our relations from the periodic nature of $\upsilon$ and $G$ \eqref{eqn:fourierfactor}, and the reconstructions $\mathcal{R}^+$ and $\mathcal{R}^-$ used on $G$ to obtain $G^+_{j +1/2}$ and $G^-_{j +1/2}$ respectively we obtain
 
 \begin{multline*}
 \sum_j \frac{\Delta x}{6}\begin{bmatrix} e^{-ik\Delta x} \mathcal{R}^+_2 \\2 e^{-ik\Delta x} \mathcal{R}^+_2 +2 \mathcal{R}^-_2 \\ \mathcal{R}^-_2 \end{bmatrix} G_j = \\\sum_j \Bigg(H\frac{\Delta x}{30}\begin{bmatrix} 4e^{-ik\frac{\Delta x}{2}} +  2 - e^{ik\frac{\Delta x}{2}}\\2e^{-ik\frac{\Delta x}{2}}  + 16  +2 e^{ik\frac{\Delta x}{2}}  \\ -e^{-ik\frac{\Delta x}{2}} +  2 + 4e^{ik\frac{\Delta x}{2}} \end{bmatrix} \\+ \frac{H^3 }{9\Delta x}\begin{bmatrix} 7e^{-ik\frac{\Delta x}{2}} -8 + e^{ik\frac{\Delta x}{2}} \\ -8e^{-ik\frac{\Delta x}{2}} +  16  -8e^{ik\frac{\Delta x}{2}} \\ e^{-ik\frac{\Delta x}{2}} -8 + 7e^{ik\frac{\Delta x}{2}} \end{bmatrix}  \Bigg) \upsilon_j.
 \end{multline*}
 
 We can now add all the terms that overlap i.e the extra contributions from the functions $\phi_{j+1/2}$ and $\phi_{j-1/2}$ from outside the cell $\left[x_{j-1/2}, x_{j+1/2}\right]$, this then gives us a relation between sub-vectors and sub-matrices of the FEM. In particular we get that
 \begin{multline*}
\frac{\Delta x}{6}\begin{bmatrix} 2  \\ \mathcal{R}^-_2 + \mathcal{R}^+_2 \end{bmatrix}^T \begin{bmatrix} G_j  \\ G_j\end{bmatrix}  = \\ \Bigg(H\frac{\Delta x}{30}\begin{bmatrix}2e^{-ik\frac{\Delta x}{2}}  + 16  +2 e^{ik\frac{\Delta x}{2}} \\ -e^{-ik\frac{\Delta x}{2}} +  2 + 4e^{ik\frac{\Delta x}{2}} + e^{ik{\Delta x}}\left(4e^{-ik\frac{\Delta x}{2}} +  2 - e^{ik\frac{\Delta x}{2}}\right) \end{bmatrix}^T  \\+ \frac{H^3 }{9\Delta x}\begin{bmatrix}  -8e^{-ik\frac{\Delta x}{2}} +  16  -8e^{ik\frac{\Delta x}{2}} \\  e^{-ik\frac{\Delta x}{2}} -8 + 7e^{ik\frac{\Delta x}{2}}  + e^{ik{\Delta x}}\left(7e^{-ik\frac{\Delta x}{2}} -8 + e^{ik\frac{\Delta x}{2}}  \right)\end{bmatrix}^T    \Bigg) \begin{bmatrix} \upsilon_j  \\ \upsilon_{j+1/2} \end{bmatrix}.
 \end{multline*}
 
 Which reduces to
 
\begin{multline*}
\frac{\Delta x}{6}\begin{bmatrix} 2  \\ \mathcal{R}^-_2 + \mathcal{R}^+_2 \end{bmatrix}^T \begin{bmatrix} G_j  \\ G_j\end{bmatrix}  = \\ \Bigg(H\frac{\Delta x}{30}\begin{bmatrix} 16  + 4 \cos\left(\frac{k \Delta x}{2}\right) \\ 2e^{ik\frac{\Delta x}{2}}\left(2\cos\left(\frac{k \Delta x}{2}\right) - \cos\left({k \Delta x}\right) + 4\right)  \end{bmatrix}^T  \\+ \frac{H^3 }{9\Delta x}\begin{bmatrix}  16  -16\cos\left(\frac{k \Delta x}{2}\right) \\  -8e^{ik\frac{\Delta x}{2}} \sin^2\left(\frac{k \Delta x}{4}\right)\left(\cos\left(\frac{k \Delta x}{2}\right) - 3 \right)    \end{bmatrix}^T    \Bigg) \begin{bmatrix} \upsilon_j  \\ \upsilon_{j} \end{bmatrix}.
\end{multline*}
 
 %diagonal matrix with the eigenvalues
 
 So the equation for $\upsilon_{j+1/2}$ given by the second element of the vector is
 
 \begin{multline*}
 \frac{\Delta x}{6}\left(\mathcal{R}^+_2 +\mathcal{R}^-_2\right)  G_j = \\ \Bigg(H\frac{\Delta x}{30} \left(2e^{ik\frac{\Delta x}{2}} \left(2\cos\left(\frac{k \Delta x}{2}\right) - \cos\left({k \Delta x}\right) + 4\right)\right) \\+ \frac{H^3 }{9\Delta x}\left(-8e^{ik\frac{\Delta x}{2}} \sin^2\left(\frac{k \Delta x}{4}\right)\left(\cos\left(\frac{k \Delta x}{2}\right) - 3 \right) \right)   \Bigg)  \upsilon_{j}.
 \end{multline*}
 
 So we have
  \begin{multline*}
 G_j = \frac{6}{\Delta x} \frac{1}{\mathcal{R}^+_2 +\mathcal{R}^-_2} \\ \times \Bigg(H\frac{\Delta x}{30} \left(2e^{ik\frac{\Delta x}{2}} \left(2\cos\left(\frac{k \Delta x}{2}\right) - \cos\left({k \Delta x}\right) + 4\right)\right) \\+ \frac{H^3 }{9\Delta x}\left(-8e^{ik\frac{\Delta x}{2}} \sin^2\left(\frac{k \Delta x}{4}\right)\left(\cos\left(\frac{k \Delta x}{2}\right) - 3 \right) \right)   \Bigg)  \upsilon_{j}.
  \end{multline*}

 
Therefore,
  \begin{multline*}
  \mathcal{G}_{FEM2}  = \frac{6}{\Delta x} \frac{1}{\mathcal{R}^+_2 +\mathcal{R}^-_2} \\ \times \Bigg(H\frac{\Delta x}{30} \left(2e^{ik\frac{\Delta x}{2}} \left(2\cos\left(\frac{k \Delta x}{2}\right) - \cos\left({k \Delta x}\right) + 4\right)\right) \\+ \frac{H^3 }{9\Delta x}\left(-8e^{ik\frac{\Delta x}{2}} \sin^2\left(\frac{k \Delta x}{4}\right)\left(\cos\left(\frac{k \Delta x}{2}\right) - 3 \right) \right)   \Bigg).
  \end{multline*}
 This is the numerical method's transformation coefficient between $G_j$ and $\upsilon_{j+1/2}$, the only $\upsilon$ value we need for our numerical method. Consequently, the FEM does use the analytic value for the reconstruction method $\mathcal{R}^\upsilon$.


\subsection{Conservation Equation}
Finite volume methods have the following update scheme to approximate equations in conservation law form for some quantity $q$ \eqref{eqn:evolupdatescheme}
\begin{equation*}
%\label{eqn:ConUpdateForm}
\bar{q}^{\,n + 1}_{j} = \bar{q}^{\,n}_{j} - \frac{\Delta t}{\Delta x} \left[F^{\,n} _{j+1/2} - F^{\,n} _{j-1/2} \right].
\end{equation*}


Where the bar denotes that it is the spatial average of the quantity $q$ over the cell and $F^{\,n} _{j+1/2}$ and $F^{\,n} _{j-1/2}$ are the approximations to the temporal average of the fluxes across the cell boundary between the times $t^n$ and $t^{n+1}$. 

In our methods there is some transformation between the nodal value $q_j$ and the cell average $\bar{q}_j$, which produces some factor $\mathcal{M}$. For first and second order methods $\mathcal{M}_1 = \mathcal{M}_2 = 1$, however for higher-order methods $\mathcal{M} \neq 1$. Because of this we will highlight the transformations between cell averages and nodal values for this second-order example with $\mathcal{M}_2$ even though it is simply unity, so as to guide the reader if they wish to replicate this work for higher-order methods. The multiplier $\mathcal{M}_3$ will be given in subsection \ref{subsec:TabFacdisp} and is simple to calculate since if ${q}_j$ is a fourier mode then so is $\bar{q}_j$.

To calculate the fluxes $F^{\,n} _{j+1/2}$ and $F^{\,n} _{j-1/2}$ we use Kurganov's method \cite{Kurganov-etal-2001-707} which is 
\begin{equation*}
F_{j+\frac{1}{2}} = \dfrac{a^+_{j+\frac{1}{2}} f\left(q^-_{j+\frac{1}{2}}\right) - a^-_{j+\frac{1}{2}} f\left(q^+_{j+\frac{1}{2}}\right)}{a^+_{j+\frac{1}{2}} - a^-_{j+\frac{1}{2}}}  + \dfrac{a^+_{j+\frac{1}{2}} \, a^-_{j+\frac{1}{2}}}{a^+_{j+\frac{1}{2}} - a^-_{j+\frac{1}{2}}} \left [ q^+_{j+\frac{1}{2}} - q^-_{j+\frac{1}{2}} \right ]
\end{equation*}
where $a^+_{j+\frac{1}{2}}$ and $a^-_{j+\frac{1}{2}}$ are given by the wave speed bounds \eqref{eqn:WaveVelocitiesBound}, so that 

\[a^-_{j+ 1/2} =  - \sqrt{g H}\]
and
\[a^+_{j+ 1/2} = \sqrt{g H}.\]
We have suppressed the superscripts denoting the time to simplify the notation as all times are now $t^n$ in the flux calculation. Substituting these values into the flux approximation we obtain 

\begin{equation}\label{eqn:HLL_fluxred}
F_{j+\frac{1}{2}} = \dfrac{ f\left(q^-_{j+\frac{1}{2}}\right) + f\left(q^+_{j+\frac{1}{2}}\right)}{ 2}  - \dfrac{ \sqrt{gH}}{ 2} \left [ q^+_{j+\frac{1}{2}} - q^-_{j+\frac{1}{2}} \right ]
\end{equation}

The Kurganov approximation to the flux of $\eta$ \eqref{eqn:LinContG} is
\begin{equation}
\label{eqn:HLL_fluxeta}
F^{\eta}_{j+\frac{1}{2}} = \dfrac{ H \upsilon ^-_{j+\frac{1}{2}}+ H \upsilon ^+_{j+\frac{1}{2}}}{ 2}  - \dfrac{ \sqrt{gH}}{ 2} \left [ \eta^+_{j+\frac{1}{2}} - \eta^-_{j+\frac{1}{2}} \right ]
\end{equation}

The missing pieces here are the factors introduced by the reconstruction of the edge values $\upsilon ^-_{j+\frac{1}{2}}$, $\upsilon ^+_{j+\frac{1}{2}}$, $\eta ^-_{j+\frac{1}{2}}$ and $\eta ^+_{j+\frac{1}{2}}$ from the cell averages $\bar{\eta}_j$ and the nodal values ${\upsilon}_j$. Because our quantities are smooth the nonlinear limiters can be neglected so we have for the second-order reconstruction of $\eta$ 

\begin{equation*}
\eta^-_{j+\frac{1}{2}} = \bar{\eta}_j + \frac{- \bar{\eta}_{j - 1} + \bar{\eta}_{j+ 1} }{4}
\end{equation*}
and
\begin{equation*}
\eta^+_{j+\frac{1}{2}} = \bar{\eta}_{j+1} + \frac{- \bar{\eta}_{j} + \bar{\eta}_{j+ 2}}{4}.
\end{equation*}
	
Using \eqref{eqn:fourierfactor} these equations become

\begin{equation*}
\eta^-_{j+\frac{1}{2}} = \mathcal{M}_2{\eta}_j + \frac{- \mathcal{M}_2{\eta}_{j} e^{-ik\Delta x} + \mathcal{M}_2{\eta}_{j} e^{ik\Delta x}}{4}
\end{equation*}
and
\begin{equation*}
\eta^+_{j+\frac{1}{2}} = \mathcal{M}_2{\eta}_{j}e^{ik\Delta x} + \frac{- \mathcal{M}_2{\eta}_{j} + \mathcal{M}_2{\eta}_{j}e^{2ik\Delta x} }{4}.
\end{equation*}

For the second order case $\mathcal{M}_2 = 1$ and these equations can be reduced to 

\begin{equation*}
\eta^-_{j+\frac{1}{2}} = \left(1  + \frac{i\sin\left(k\Delta x\right)}{2} \right){\eta}_j
\end{equation*}
and
\begin{equation*}
\eta^+_{j+\frac{1}{2}} = e^{ik\Delta x}\left(1  - \frac{i\sin\left(k\Delta x\right)}{2} \right){\eta}_{j}.
\end{equation*}
	
We introduce the second order reconstruction factors\\ $\mathcal{R}^+_2 = e^{ik\Delta x}\left(1  - \frac{i\sin\left(k\Delta x\right)}{2} \right)$ and $\mathcal{R}^-_2 = 1  + \frac{i\sin\left(k\Delta x\right)}{2}$ for both $\eta$ and $G$. So that we have 

\begin{equation*}
\eta^-_{j+\frac{1}{2}} = \mathcal{R}^-_2 {\eta}_j
\end{equation*}
\begin{equation*}
\eta^+_{j+\frac{1}{2}} = \mathcal{R}^+_2{\eta}_{j}.
\end{equation*}

In our numerical methods the reconstruction of $\upsilon$ is slightly different as $\upsilon ^-_{j+\frac{1}{2}}$ and $\upsilon ^+_{j+\frac{1}{2}}$ are equal as we assume $\upsilon$ is continuous. For the second order finite difference volume method we have

\begin{equation*}
\upsilon^-_{j + 1/2} = \upsilon^+_{j + 1/2} = \frac{\upsilon_{j+1} + \upsilon_{j}}{2}
\end{equation*}

Using \eqref{eqn:fourierfactor} and rearranging gives

\begin{equation*}
\label{eqn:2ndreconu}
\upsilon^-_{j + 1/2} = \upsilon^+_{j + 1/2} = \frac{e^{ik\Delta x } + 1}{2} \upsilon_{j}.
\end{equation*}

We therefore introduce the second order reconstruction error factor $\mathcal{R}^\upsilon_{FD2} = \frac{e^{ik\Delta x } + 1}{2}$. Because our FEM for the elliptic equation \ref{eqn:LinConSerreGu0} calculates $\upsilon_{j+1/2}$ from $G_j$ we do not need to reconstruct $\upsilon_{j+1/2}$ and so we have that $\mathcal{R}^\upsilon_{FEM2} = e^{ik\frac{\Delta x}{2} }$, which corresponds to calculating $\upsilon_{j+1/2}$ analytically given $\upsilon_{j}$. 

Substituting these reconstruction coefficients into \eqref{eqn:HLL_fluxeta} results in
\begin{equation*}
F^{\eta}_{j+\frac{1}{2}} = \dfrac{ H  \mathcal{R}^\upsilon_{FD2} \upsilon_{j}+ H\mathcal{R}^\upsilon_{FD2} \upsilon_{j}}{ 2}  - \dfrac{ \sqrt{gH}}{ 2} \left [  \mathcal{R}^+_2 {\eta}_j -  \mathcal{R}^-_2{\eta}_j \right ]
\end{equation*}

Which becomes

\begin{equation*}
F^{\eta}_{j+\frac{1}{2}} = H \mathcal{R}^\upsilon_{FD2} \upsilon_{j}   - \dfrac{ \sqrt{gH}}{ 2} \left [  \mathcal{R}^+_2 -  \mathcal{R}^-_2 \right ] {\eta}_j
\end{equation*}

We then introduce the factors $\mathcal{F}^{\eta,\upsilon}_{FD2}$ and $\mathcal{F}^{\eta,\eta}_{FD2}$
\begin{align}
\label{eqn:FluxFactorsh}
\mathcal{F}^{\eta,\eta}_{FD2} & = - \dfrac{ \sqrt{gH}}{ 2} \left [  \mathcal{R}^+_2 -  \mathcal{R}^-_2 \right ],\\
\mathcal{F}^{\eta,\upsilon}_{FD2} & = H \mathcal{R}^\upsilon_{FD2}
\end{align}
so that
\begin{equation}
\label{eqn:etafluxapprox}
F^{\eta}_{j+\frac{1}{2}} = \mathcal{F}^{\eta,\upsilon}_{FD2} \upsilon_{j}   +  \mathcal{F}^{\eta,\eta}_{FD2} {\eta}_j.
\end{equation}


The Kurganov approximation \eqref{eqn:HLL_fluxred} to the flux average for $G$ \eqref{eqn:LinContG} is
\begin{equation*}
F^{G}_{j+\frac{1}{2}} = \dfrac{ gH \eta ^-_{j+\frac{1}{2}}+ gH \eta ^+_{j+\frac{1}{2}}}{ 2}  - \dfrac{ \sqrt{gH}}{ 2} \left [ G^+_{j+\frac{1}{2}} - G^-_{j+\frac{1}{2}} \right ].
\end{equation*}

Repeating the process above for $F^{G}_{j+\frac{1}{2}}$ we get that
\begin{equation}
\label{eqn:Gfluxapprox}
F^{G}_{j+\frac{1}{2}} =  \mathcal{F}^{G,\eta}_{FD2} \eta_{j}  + \mathcal{F}^{G,\upsilon}_{FD2}\upsilon_j
\end{equation}
where
\begin{align}
\label{eqn:FluxFactorsG}
\mathcal{F}^{G,\eta}_{FD2} & = gH \dfrac{\mathcal{R}^-_2 + \mathcal{R}^+_2 }{ 2}, \\
\mathcal{F}^{G,\upsilon}_{FD2} & = - \dfrac{ \sqrt{gH}}{ 2} \left [  \mathcal{R}^+_2 -  \mathcal{R}^-_2 \right ] \mathcal{G}.
\end{align}

By substituting \eqref{eqn:etafluxapprox}, \eqref{eqn:Gfluxapprox} into \eqref{eqn:evolupdatescheme} our finite volume method can be written as

\begin{equation*}
\mathcal{M}_2 \eta^{\,n + 1}_{j} = \mathcal{M}_2 \eta^{\,n }_{j} - \frac{\Delta t}{\Delta x}  \left[ \left(1 - e^{ik\Delta x}\right) \left(\mathcal{F}_{FD2}^{\eta,\eta} h_{j}  + \mathcal{F}_{FD2}^{\eta,\upsilon} \upsilon_j \right) \right],
\end{equation*}
\begin{equation*}
\mathcal{M}_2 G^{\,n + 1}_{j} = \mathcal{M}_2 G^{\,n }_{j} - \frac{\Delta t}{\Delta x}  \left[ \left(1 - e^{ik\Delta x}\right) \left(  \mathcal{F}_{FD2}^{G,\eta} \eta_{j}  + \mathcal{F}_{FD2}^{G,\upsilon} \upsilon_j \right) \right].
\end{equation*}
	
Furthermore by transforming the $G$'s into $\upsilon$'s using our second order finite volume factor $\mathcal{G}_{FD2}$ we obtain
	
\begin{align*}
\eta^{\,n + 1}_{j} &= \eta^{\,n }_{j} - \frac{1}{\mathcal{M}_2}\frac{\Delta t}{\Delta x}  \left[ \left(1 - e^{ik\Delta x}\right) \left(\mathcal{F}_{FD2}^{\eta,\eta} \eta_{j}  + \mathcal{F}_{FD2}^{\eta,\upsilon} \upsilon_j \right) \right], \\
\upsilon^{\,n + 1}_{j} &= \upsilon^{\,n }_{j} -  \frac{1}{\mathcal{G}_{FD2} \mathcal{M}_2}\frac{\Delta t}{\Delta x}  \left[ \left(1 - e^{ik\Delta x}\right) \left(  \mathcal{F}_{FD2}^{G,\eta} \eta_{j}  + \mathcal{F}_{FD2}^{G,\upsilon} \upsilon_j \right) \right].
\end{align*}

This can be written in matrix form as

\begin{equation*}
\begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n+1}_j = \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j - \frac{\left(1 - e^{ik\Delta x}\right) \Delta t}{\Delta x}\begin{bmatrix}
\frac{1}{\mathcal{M}_2} \mathcal{F}_{FD2}^{\eta,\eta} & \frac{1}{\mathcal{M}_2}\mathcal{F}_{FD2}^{\eta,\upsilon} \\ \frac{1}{\mathcal{G}_{FD2} \mathcal{M}_2}\mathcal{F}_{FD2}^{\upsilon,\eta} & \frac{1}{\mathcal{G}_{FD2} \mathcal{M}_2}\mathcal{F}_{FD2}^{\upsilon,\upsilon} 
\end{bmatrix}\begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j
\end{equation*}

Introducing the matrix
\begin{equation}
\label{eqn:FluxFactorMatrix}
\matr{F}_{FD2} = \frac{\left(1 - e^{ik\Delta x}\right)}{\Delta x}\begin{bmatrix}
\frac{1}{\mathcal{M}_2}\mathcal{F}_{FD2}^{\eta,\eta} & \frac{1}{\mathcal{M}_2}\mathcal{F}_{FD2}^{\eta,\upsilon} \\ \frac{1}{\mathcal{M}_2\mathcal{G}_{FD2}}\mathcal{F}_{FD2}^{\upsilon,\eta} &  \frac{1}{\mathcal{M}_2\mathcal{G}_{FD2}}\mathcal{F}_{FD2}^{\upsilon,\upsilon} 
\end{bmatrix}
\end{equation}

this becomes

\begin{equation*}
\label{eqn:matrixevolupdate}
\begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n+1}_j = \left(\matr{I}  - \Delta t \matr{F}_{FD2} \right) \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j
\end{equation*}
So we have created the desired equation and derived all the factors introduced by the various operators of the second order FDVM. The second-order FEVM is very similar except it uses $\mathcal{G}_{FEM2}$ and $\mathcal{R}^\upsilon_{FEM2}$. This update formula for one evolution step applies simply to the other FDVM provided you switch out the coefficients appropriately. We will now demonstrate how the analysis continues with the Runge-Kutta time stepping employed by our higher-order methods, again by taking the second-order case as an example.

\subsection{Runge-Kutta Time Stepping}
\label{subsec:RKstepdisp}
Since we have demonstrated this process for a single evolution step the analysis will now proceed for the Runge-Kutta time stepping that allows our schemes to be temporally higher order accurate. We will again demonstrate this process for just the second-order FDVM and omit the analysis for the other methods, presenting the results at the end.

The second order Runge Kutta time stepping proceeds as follows

\begin{subequations}
	\label{eqn:RKstepfull}
	\begin{equation}
	\label{eqn:RKstepfullp1}
	\begin{bmatrix}
	\eta \\ \upsilon
	\end{bmatrix}^{1}_j = \left(\matr{I} - \Delta t\matr{F}_{FD2} \right)\begin{bmatrix}
	\eta \\ \upsilon
	\end{bmatrix}^{n}_j,
	\end{equation}
	
	\begin{equation}
	\label{eqn:RKstepfullp2}
	\begin{bmatrix}
	\eta \\ \upsilon
	\end{bmatrix}^{2}_j = \left(\matr{I} - \Delta t\matr{F}_{FD2} \right)\begin{bmatrix}
	\eta \\ \upsilon
	\end{bmatrix}^{1}_j
	\end{equation}
		
	\begin{equation}
	\label{eqn:RKstepfullp3}
	\begin{bmatrix}
	\eta \\ \upsilon
	\end{bmatrix}^{n+1}_j = \frac{1}{2} \left(\begin{bmatrix}
	\eta \\ \upsilon
	\end{bmatrix}^{n}_j + \begin{bmatrix}
	\eta \\ \upsilon
	\end{bmatrix}^{2}_j\right) 
	\end{equation}
\end{subequations}


Substituting \eqref{eqn:RKstepfullp1} and \eqref{eqn:RKstepfullp2} into \eqref{eqn:RKstepfullp3} we can write this in terms of the spatially second-order operator $\matr{F}_{FD2}$ and the primitive variables at $t^n$
\begin{equation*}
\begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n+1}_j = \frac{1}{2} \left(\begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j + \left(\matr{I} - \Delta t\matr{F}_2 \right)^2 \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j\right).
\end{equation*}

Expanding $\left(\matr{I} - \Delta t\matr{F}_{FD2} \right)^2$ we get

\begin{equation*}
\begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n+1}_j = \frac{1}{2} \left(2\matr{I}  -2\Delta t\matr{F}_{FD2} + \Delta t^2\matr{F}^2_{FD2} \right) \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j.
\end{equation*}

Provided that an eigenvalue decomposition $\matr{F}_{FD2} = \matr{P} \matr{\Lambda} \matr{P}^{-1} $ exists our equation can be rewritten as 

\begin{equation*}
\begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n+1}_j = \frac{1}{2} \left(2\matr{I}  -2\Delta t\matr{P} \matr{\Lambda} \matr{P}^{-1}  + \Delta t^2\matr{P} \matr{\Lambda}^2 \matr{P}^{-1} \right) \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j.
\end{equation*}

Multiplying both sides by $\matr{P}^{-1}$ on the left and rearranging this equation we obtain

\begin{equation*}
\matr{P}^{-1} \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n+1}_j = \frac{1}{2} \left(2 -2\Delta t \matr{\Lambda}  + \Delta t^2 \matr{\Lambda}^2  \right)  \matr{P}^{-1} \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j.
\end{equation*}

Since $\eta$ and $\upsilon$ are Fourier modes we have by \eqref{eqn:fourierfactor} that

\begin{equation*}
e^{i\omega \Delta t} \left(\matr{P}^{-1} \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j  \right)= \left(1 -1\Delta t \matr{\Lambda}  + \frac{1}{2}\Delta t^2 \matr{\Lambda}^2  \right)  \left(\matr{P}^{-1} \begin{bmatrix}
\eta \\ \upsilon
\end{bmatrix}^{n}_j  \right).
\end{equation*}

Since $\matr{\Lambda}$ is a diagonal matrix consisting of the eigenvalues $\lambda_1$ and $\lambda_2$ we have that

\begin{align*}
e^{i\omega\Delta t} &= 1 + \frac{1}{2}\Delta t^2 \lambda_{1}^2  -\Delta t\lambda_{1}, \\
e^{i\omega\Delta t} &= 1 + \frac{1}{2}\Delta t^2 \lambda_{2}^2  -\Delta t\lambda_{2}.
\end{align*}

So that the dispersion relation for the second order finite difference finite volume method is

\begin{align}
\label{eqn:DispersionRelationSecondOrder}
\omega &= \frac{1}{i \Delta t} \ln \left(1 + \frac{1}{2}\Delta t^2 \lambda_{1}^2  -\Delta t\lambda_{1}\right), \\
\omega &= \frac{1}{i \Delta t} \ln \left(1 + \frac{1}{2}\Delta t^2 \lambda_{2}^2  -\Delta t\lambda_{2}\right).
\end{align}
Where $\lambda_{1}$ and $\lambda_{2}$ are the eigenvalues of $\matr{F}_{FD2}$. The equation is the very similar for the FEVM as it uses second-order Runge Kutta time stepping, with the eigenvalues of $\matr{F}_{FEM2}$ instead of $\matr{F}_{FD2}$. By comparing this with the dispersion relation \eqref{eqn:DispersionRelation} of the Serre equations we can determine the error in dispersion caused by the particular method.

For the first-order time stepping we get that
\begin{align}
\label{eqn:DispersionRelationFirstOrder}
\omega &= \frac{1}{i \Delta t} \ln \left(1 -\Delta t\lambda_{1}\right), \\
\omega &= \frac{1}{i \Delta t} \ln \left(1 -\Delta t\lambda_{2}\right),
\end{align}
where $\lambda_1$ and $\lambda_2$ are the eigenvalues of $\matr{F}_1$ which uses the appropriate first-order FDVM.

For the third-order Runge Kutta steps we get that
\begin{align}\label{eqn:DispersionRelationThirdOrder}
\omega &= \frac{1}{i \Delta t} \ln \left(1 - \frac{1}{6}\Delta t^3 \lambda_{1}^3  + \frac{1}{2}\Delta t^2 \lambda_{1}^2  -\Delta t\lambda_{1}\right), \\
\omega &= \frac{1}{i \Delta t} \ln \left(1 - \frac{1}{6}\Delta t^3 \lambda_{2}^3  + \frac{1}{2}\Delta t^2 \lambda_{2}^2  -\Delta t\lambda_{2}\right),
\end{align}
where $\lambda_1$ and $\lambda_2$ are the eigenvalues of $\matr{F}_3$ which uses the appropriate third-order FDVM.

We now proceed to present the tables of the factors generated by the operators $\mathcal{M}$, $\mathcal{G}$, $\mathcal{R}^+$, $\mathcal{R}^-$ and $\mathcal{R}^{\upsilon}$. Condensing both the results from the example given above as well as the factors for the first and third-order FDVM. 

\subsection{Tables of Factors}
\label{subsec:TabFacdisp}
In the following we present tables which give both the formula for the fundamental approximations and the lowest order term of the Taylor series for the error between the approximation and the analytic value. In particular we take the error to be the value of the approximation minus the analytic value. We use subscripts to denote the order of accuracy of the approximation, and where necessary specify the specific method for the two different second-order methods. We use subscript $A$ to denote the analytic value of the operator. Finally we also present the error for the elements of the flux matrix $\matr{F}$ to demonstrate that when combined the pieces of our numerical method do indeed provide us with the correct spatial order of accuracy.
\begin{table}
	\centering
	\begin{tabular}{l  c  c}
		Variable& Formula& Lowest Order Term of Error \\
		\hline && \\
		$\mathcal{M}_A$& $\dfrac{2}{k \Delta x } \sin\left(\dfrac{k\Delta x}{2}\right)$ & $-$ \\ & & \\
		$\mathcal{M}_1$& $1$ & $\dfrac{1}{24}k^2 \Delta x^2$ \\ & & \\
		$\mathcal{M}_2$& $1$ & $\dfrac{1}{24}k^2 \Delta x^2$ \\ & & \\
		$\mathcal{M}_3$& $\dfrac{24}{26 - 2 \cos\left(k \Delta x\right)}$ & $\dfrac{3}{640}k^4 \Delta x^4$ \\ & & \\
	\end{tabular}
	\caption{Factor $\mathcal{M}$ from transformation between nodal and cell average values}
	\label{tab:Mfactor}
\end{table}

\begin{table}
\centering
	\begin{tabular}{l  c  c}
		Variable& Formula& Lowest Order Term of Error\\
		\hline && \\
		$\mathcal{R}^+_A$& $\exp\left(i k \dfrac{\Delta x}{2}\right)$ & $-$ \\ & & \\
		$\mathcal{R}^+_1$& $\exp\left(i k {\Delta x}\right)$ & $\dfrac{i}{2}k \Delta x$ \\ & & \\
		$\mathcal{R}^+_2$& $\exp\left(i k {\Delta x}\right) \left(1 - \dfrac{i \sin\left(k\Delta x \right)}{2} \right)$ & $\dfrac{1}{8}k^2 \Delta x^2$ \\ & & \\
		$\mathcal{R}^+_3$& $\dfrac{2\exp\left(2ik \Delta x\right) - 10\exp\left(ik \Delta x\right) - 4}{\cos\left(k \Delta x\right) - 13}$ & $\dfrac{i}{12}k^3 \Delta x^3$ \\ & & \\
	\end{tabular}
	\caption{Factor $\mathcal{R}^+$ from reconstruction at $x_{j+1/2}$ from cell $C_{i+1}$ for $\eta$ and $G$}
	\label{tab:Rpfactor}
\end{table}

\begin{table}
	\centering
	\begin{tabular}{l  c  c}
	 	Variable& Formula& Lowest Order Term of Error\\
	 	\hline && \\
	 	$\mathcal{R}^-_A$& $\exp\left(i k \dfrac{\Delta x}{2}\right)$ & $-$ \\ & & \\
	 	$\mathcal{R}^-_1$& $1$ & $-\dfrac{i}{2}k \Delta x$ \\ & & \\
	 	$\mathcal{R}^-_2$& $1 +  \dfrac{i \sin\left(k\Delta x \right)}{2}$ & $\dfrac{1}{8}k^2 \Delta x^2$ \\ & & \\
	 	$\mathcal{R}^-_3$& $\dfrac{2 \exp\left(-i k \Delta x\right) - 4\exp\left(i k \Delta x\right) - 10}{\cos\left(k \Delta x\right) - 13}$ & $-\dfrac{i}{12}k^3 \Delta x^3$ \\ & & \\
	\end{tabular}
	\caption{Factor $\mathcal{R}^-$ from reconstruction at $x_{j+1/2}$ from cell $C_{i}$ for $\eta$ and $G$}
	\label{tab:Rmfactor}
\end{table}

\begin{table}
	\centering
	\begin{tabular}{l  c  c}
	   	Variable& Formula& Lowest Order Term of Error\\
	   	\hline && \\
	   	$\mathcal{R}^\upsilon_A$& $\exp\left(i k \dfrac{\Delta x}{2}\right)$ & $-$ \\ & & \\
	   	$\mathcal{R}^\upsilon_1$& $\dfrac{\exp\left(i k \Delta x\right) + 1}{2}$ & $-\dfrac{1}{8} k^2 \Delta x^2$ \\ & & \\
	   	$\mathcal{R}^\upsilon_{FD2}$& $\dfrac{\exp\left(i k \Delta x\right) + 1}{2}$ & $-\dfrac{1}{8}k^2 \Delta x^2$ \\ & & \\
	   	$\mathcal{R}^\upsilon_{FEM2}$ & $\exp\left(i k \dfrac{\Delta x}{2}\right)$ & $0$ \\& & \\
	   	$\mathcal{R}^\upsilon_3$& $\dfrac{-\exp\left(-ik \Delta x\right) + 9 \exp\left(ik \Delta x\right) -\exp\left(2ik \Delta x\right) + 9}{16}$ & $-\dfrac{3}{128}k^4 \Delta x^4$ \\ & & \\
	\end{tabular}
	\caption{Factor $\mathcal{R}^\upsilon$ from reconstruction at $x_{j+1/2}$ for $\upsilon$}
    \label{tab:Rufactor}
\end{table}

\begin{table}
	\centering   
	\begin{tabular}{l  c  c}
	      	Variable& Formula& Lowest Order Term of Error\\
	      	\hline && \\
	      	$\mathcal{G}_A$& $H + \dfrac{H^3}{3}k^2$ & $-$ \\ & & \\
	      	$\mathcal{G}_1$& $H - \dfrac{H^3}{3}\dfrac{2\cos\left(k \Delta x\right) -2}{\Delta x^2}$ & $-\dfrac{H^3}{36}k^4 \Delta x ^2$ \\ & & \\
	      	$\mathcal{G}_{2FD}$& $H - \dfrac{H^3}{3}\dfrac{2\cos\left(k \Delta x\right) -2}{\Delta x^2}$ & $-\dfrac{H^3}{36}k^4 \Delta x ^2$ \\ & & \\
	  $\mathcal{G}_{2FEM}$& $*$ & $-\dfrac{3 H}{40}k^2 \Delta x^2 - \dfrac{H^3}{36}k^4 \Delta x^2$ \\ & & \\
	      	$\mathcal{G}_3$& $H - \dfrac{H^3}{3}\dfrac{32\cos\left(k \Delta x\right) -2\cos\left(2k \Delta x\right) - 30}{12 \Delta x^2}$ & $-\dfrac{H^3}{270}k^6 \Delta x ^4$ \\ & & \\ 
	\end{tabular}
	\caption{Factor $\mathcal{G}$ from solving the elliptic equation \eqref{eqn:LinConSerreGu0}}
	\label{tab:Gfactor} 
	\begin{multline*}
	\mathcal{G}_{2FEM} =  \Bigg(\dfrac{2 H^3}{3 \Delta x ^2} \left(\exp\left(ik \dfrac{3\Delta x}{2}\right) + 14 \exp\left(ik \dfrac{\Delta x}{2}\right) - 8 \exp\left(ik\Delta x\right) - 8 + \exp\left(-ik \dfrac{\Delta x}{2}\right)\right) \\ + \dfrac{H}{5}\left(-\exp\left(ik \dfrac{3\Delta x}{2}\right) + 8 \exp\left(ik \dfrac{\Delta x}{2}\right) + 2\exp\left(ik \Delta x\right) + 2 - \exp\left(-ik \dfrac{\Delta x}{2}\right)\right) \Bigg) \div \\\left( - \dfrac{1}{4} \exp\left(2 i \Delta x k\right) + \exp\left(i \Delta x k\right) + \dfrac{i}{2} \sin\left(k\Delta x\right) + \dfrac{5}{4} \right) 
	\end{multline*}
\end{table}
        
\begin{table}
\centering
	\begin{adjustbox}{angle=90}
	  \begin{tabular}{l c c c c c}
	     	Variable& Exact &\multicolumn{4}{l}{Lowest Order Truncation Term}\\
	     	 & &  \multicolumn{4}{l}{\rule{1\textwidth}{0.4pt}} \\
	     	 & & $\text{FDVM}_1$& $\text{FDVM}_2$& $\text{FEVM}_2$ & $\text{FDVM}_3$ \\
	     	 \hline \\
	     	$ \frac{\mathcal{D}}{\mathcal{M}\Delta x}\mathcal{F}^{\eta,\eta}$& $0$ & $\frac{\sqrt{gH}}{2}k^2 \Delta x$&$\frac{\sqrt{gH}}{8}k^4 \Delta x^3$& $\frac{\sqrt{gH}}{8}k^4 \Delta x^3$ & $\frac{\sqrt{gH}}{12}k^4 \Delta x^3$ \\ [5mm]
	     	$\frac{\mathcal{D}}{\mathcal{M}\Delta x} \mathcal{F}^{\eta,\upsilon}$& $ikH$  &$ -\frac{iH}{6} k^3 \Delta x^2$&$ -\frac{iH}{6} k^3 \Delta x^2$& $ -\frac{iH}{24} k^3 \Delta x^2$ & $ -\frac{9iH}{320} k^5 \Delta x^4$ \\ [5mm]
	  	    $ \frac{\mathcal{D}}{\mathcal{G}\mathcal{M}\Delta x} \mathcal{F}^{G,\eta}$& $\dfrac{3ikgH}{H^2k^2 +3}$ & $-\frac{ig\left(H^2k^2 + 6\right)}{4\left(H^2k^2 +3\right)^2} k^3 \Delta x^2$ & $\frac{ig\left(2H^2k^2 + 3\right)}{4\left(H^2k^2 +3\right)^2} k^3 \Delta x^2$& $\frac{ig\left(20H^2k^2 + 57 \right)}{40\left(H^2k^2 +3\right)^2} k^3 \Delta x^2$ & $-\frac{ig\left(2H^2k^2 + 9\right)}{30\left(H^2k^2 +3\right)^2}k^5 \Delta x^4$ \\  [5mm]
	  	    $\frac{\mathcal{D}}{\mathcal{G}\mathcal{M}\Delta x} \mathcal{F}^{G,\upsilon}$& $0$ & $\frac{\sqrt{gH}}{2}k^2 \Delta x$&$\frac{\sqrt{gH}}{8}k^4 \Delta x^3$& $\frac{\sqrt{gH}}{8}k^4 \Delta x^3$ & $\frac{\sqrt{gH}}{12}k^4 \Delta x^3$ \\ 
	  \end{tabular}
	\end{adjustbox}
	\caption{Elements of $\matr{F}$. Due to the length of the expression for these values we now only show the lowest order term in the Taylor series of the error and the analytic value.}
	\label{tab:Ffactor}
\end{table}

From Tables \ref{tab:Mfactor}, \ref{tab:Rpfactor}, \ref{tab:Rmfactor}, \ref{tab:Rufactor} and \ref{tab:Gfactor} we can see that the basic operators all have the correct spatial order of accuracy or better. Therefore we expect the higher order methods to outperform lower order methods, due to the smaller errors associated with the improved spatial order of accuracy.

The most notable thing about these tables is the difference between the second-order FDVM and FEVM. For most operators both have the same factor, in particular for $\mathcal{M}$ (Table~\ref{tab:Mfactor}), $\mathcal{R}^+$ (Table~\ref{tab:Rpfactor}) and $\mathcal{R}^-$ (Table~\ref{tab:Rmfactor}). The main difference between these methods comes in factors $\mathcal{G}$ (Table~\ref{tab:Mfactor}) and $\mathcal{R}^\upsilon$ (Table~\ref{tab:Rpfactor}). In particular we can see that for $\mathcal{G}$ the FDVM has a smaller error than the FEVM. Because the error is larger for the FEVM due to the presence of the $H$ term we can see that it is caused by the FEM approximations to the integral of $\upsilon H$. While the derivative approximation associated with the $H^3$ term introduces the same error for both methods. For $\mathcal{R}^\upsilon$ we can see that the FEVM performs better than the FDVM because no reconstruction is required as the FEM calculated $\upsilon_{j+1/2}$ directly. 

When these errors are combined in the construction of the flux matrix in Table~\ref{tab:Ffactor} these lead to slightly larger errors for the second-order FEVM compared to the FDVM for $\frac{\mathcal{D}}{\mathcal{G}\mathcal{M}\Delta x} \mathcal{F}^{G,\eta}$ while the error is smaller for $\frac{\mathcal{D}}{\mathcal{M}\Delta x} \mathcal{F}^{\eta,\upsilon}$.

We can also see that all these methods introduce some diffusive error for $ \frac{\mathcal{D}}{\mathcal{M}\Delta x}\mathcal{F}^{\eta,\eta}$ and $\frac{\mathcal{D}}{\mathcal{G}\mathcal{M}\Delta x} \mathcal{F}^{G,\upsilon}$. This is due to the Kurganov approximation \eqref{eqn:HLL_fluxred} containing both a flux averaging part and a diffusive part, which are nicely split for these linearised equations. In particular we have the terms $\frac{\mathcal{D}}{\mathcal{G}\mathcal{M}\Delta x} \mathcal{F}^{G,\eta}$ and $\frac{\mathcal{D}}{\mathcal{M}\Delta x} \mathcal{F}^{\eta,\upsilon}$ as the flux average part while  $\frac{\mathcal{D}}{\mathcal{M}\Delta x}\mathcal{F}^{\eta,\eta}$ and $\frac{\mathcal{D}}{\mathcal{G}\mathcal{M}\Delta x} \mathcal{F}^{G,\upsilon}$ are the diffusive part. This shows up in the errors for these terms as even powers of $\Delta x$ for the dispersive errors of the flux averaging and odd powers of $\Delta x$ for the diffusive errors introduced by the dispersive term.

Having demonstrated how to compute these factors and given expressions for the basic ones, from which the more complicated factors can be obtained we will now present our results for the dispersion error of the FDVM and FEVM.

\subsection{Results}
From the basic factors presented in the Tables \ref{tab:Mfactor}, \ref{tab:Rpfactor}, \ref{tab:Rmfactor}, \ref{tab:Rufactor} and \ref{tab:Gfactor} the flux factors $\mathcal{F}^{\eta,\eta}$,$\mathcal{F}^{\eta,\upsilon}$, $\mathcal{F}^{G,\eta}$ and $\mathcal{F}^{G,\upsilon}$
can be calculated using \eqref{eqn:FluxFactorsh} and \eqref{eqn:FluxFactorsG} respectively. From there the matrix $\matr{F}$ can be computed using \eqref{eqn:FluxFactorMatrix}, and its eigenvalues found. Having found the eigenvalues we then substitute them into the appropriate equation given by the Runge-Kutta time stepping method; \eqref{eqn:DispersionRelationFirstOrder} for first-order, \eqref{eqn:DispersionRelationSecondOrder} for second-order or \eqref{eqn:DispersionRelationThirdOrder} for third-order. 

We did this numerically for various $H$ and $k$ values and observed the behaviour of the dispersion error as we varied $\Delta x$. With $\Delta t =   \left( 0.5 / \sqrt{gH} \right) {\Delta x} $, so that we satisfy the CFL condition []. We present the results for $kH = 0.5$ and $kH = 2.5$ in Figure~\ref{fig:DispErrMeth1}. These values were chosen because of their use in \cite{Filippini-etal-2016-381}, because their results are representative for all $kH$ values and finally because they cover the physical situations we will be interested in throughout this thesis.

\begin{figure}
	\centering
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp5/figures/DispRelkh0p5.pdf}
		\subcaption*{\hspace{10 mm}$H = 1 $ and $k = 0.5$}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp5/figures/DispRelkh2p5.pdf}
		\subcaption*{\hspace{10 mm}$H = 1 $ and $k = 2.5$}
	\end{subfigure}
	\caption{Dipserion error for first-order FDVM ({\color{green!60!black} \solidrule}), second-order FDVM({\color{red} \solidrule}), second-order FEVM ({\color{blue} \solidrule})  and third-order FDVM ({\solidrule}).}
	\label{fig:DispErrMeth1}
\end{figure}

From these Figure~\ref{fig:DispErrMeth1} we can see that as expected increasing the resolution of our numerical methods decreases the dispersion error of the numerical scheme. While increasing the order of accuracy of the scheme decreases the dispersion error everywhere. 

More interesting is that the second-order FDVM performs better than the FEVM consistently across various numerical resolutions indicating that the FEVM will have a slightly larger phase error than its FDVM counterpart. Thus it appears that error in approximating $\mathcal{G}$ was more significant than the error in approximating $\mathcal{R}^{\upsilon}$ for the dispersion relation.

Our results compare well with those of \cite{Filippini-etal-2016-381} who performed a similar analysis for their numerical method applied to the linearised Serre equations with $U=0$. We have extended their results by combining the spatial and temporal contribution to the dispersion relation and performing it on a different numerical method. 

These plots only depend on the parameter $kH$ and do not vary independently for $H$ or $k$. This parameter $kH$ is proportional to the shallowness parameter $\sigma$ with $2 \pi \sigma = kH $. So for $kH=2.5$ the water is no longer shallow and the Serre equations are not an appropriate model for water waves, although our results demonstrate that our numerical methods are still well approximating the dispersion relation of the Serre equations in this case. In general we also find that as $kH$ is increased our numerical methods perform worse generally although the dispersion relation still converges to $0$ as $\Delta x \rightarrow 0$. 

We will now turn our attention to demonstrating Von Neumann stability for the two finite difference methods described in this thesis $\mathcal{D}$ and $\mathcal{W}$, and used for the purposes of comparison. We shall also see that we can use some of the previous working on the dispersion relation error to demonstrate Von Neumann stability for our FDVM and FEVM when $U=0$. 



\section{Von Neumann Stability}
To demonstrate Von Neumann stability we again begin with the linearised Serre equations \eqref{eqn:LinSerre} however will no longer require $U=0$, so we have

\begin{equation*}
	\frac{\partial  \eta}{\partial  t} + H\frac{\partial  \upsilon}{\partial  x} + U\frac{\partial  \eta}{\partial  x} = 0,
\end{equation*}
\begin{equation*}
	H\frac{\partial  \upsilon}{\partial  t} + gH\frac{\partial  \eta}{\partial  x} + UH\frac{\partial  \upsilon}{\partial  x} - \frac{H^3}{3}\left(U\frac{\partial^3  \upsilon}{\partial  x^3} + \frac{\partial^3  \upsilon}{\partial  x^3 \partial  t}  \right)  = 0.
\end{equation*}

As in the above dispersion relation analysis we will demonstrate the working for one problem and then just present the results for the other one to be repeatable and brief. Our example will be the naive second-order finite difference method $\mathcal{D}$ \eqref{eq:Dnumdef}.

We will again begin by replacing both $\eta$ and $\upsilon$ by Fourier nodes \eqref{eqn:FourierNode}. Because our approximations to derivatives is the same for $\mathcal{D}$ we will provide all the factors for the second order centred finite difference approximations to derivatives of some quantity $q$ generated by making use of \eqref{eqn:fourierfactor}. Having all the factors associated with all the spatial derivatives we are only left the task of rearranging the equations and writing it in matrix form. The factors for each derivative approximation are

\begin{subequations}
	\begin{equation}
	\left(\frac{\partial q}{\partial x}\right)^n_j = \frac{- q^n_{j-1} + q^n_{j+1}}{2 \Delta x} = \frac{i \sin\left(k \Delta x\right)}{\Delta x} q^n_j
	\end{equation}
	
	\begin{equation}
\left(\frac{\partial^2 q}{\partial x^2}\right)^n_j = \frac{q^n_{j-1} - 2q^n_j + q^n_{j+1}}{\Delta x^2} = \frac{2 \cos\left(k \Delta x\right) - 2}{\Delta x^2} q^n_j 
	\end{equation}
	\begin{equation}
	\left(\frac{\partial^3 q}{\partial x^3}\right)^n_j = \frac{- q^n_{j-2}  + 2q^n_{j-1}  - 2q^n_{j+1} + q^n_{j+2}}{2\Delta x^3}=-4i\sin\left(k \Delta x\right)\frac{\sin^2\left(\frac{k \Delta x}{2}\right) }{\Delta x^3} q^n_j
	\end{equation}
	\label{eqn:FDfactorlist}
\end{subequations}

The numerical method $\mathcal{D}$ is attained from replacing all the derivatives in \eqref{eqn:LinSerre} with the approximations in \eqref{eqn:FDfactorlist}. For the linearised equations the update formulas for $\mathcal{D}$ are

	\begin{equation*}
	\eta^{n+1}_j = \eta^{n-1}_j - \Delta t \left(U \frac{- \eta^{n}_{j-1} + \eta^{n}_{j+1} }{\Delta x} + H \frac{- \upsilon^{n}_{j-1} + \upsilon^{n}_{j+1}}{\Delta x}\right)
	\end{equation*}
	and
	\begin{multline*}
	\upsilon^{n+1}_j - \frac{H^2}{3}\frac{\upsilon^{n+1}_{j-1} -2\upsilon^{n+1}_{j} +\upsilon^{n+1}_{j+1} }{\Delta x^2} 
	\\ =  \upsilon^{n-1}_j - \frac{H^2}{3}\frac{\upsilon^{n-1}_{j-1} -2\upsilon^{n-1}_{j} +\upsilon^{n-1}_{j+1}}{\Delta x^2}   \\+  \Delta t\left(- g\frac{-\eta^n_{j-1} + \eta^n_{j+1} }{\Delta x}   - U\frac{-\upsilon^n_{j-1} + \upsilon^n_{j+1} }{\Delta x} + \frac{H^2}{3}\left(U \frac{-\upsilon^{n}_{j-2} +2\upsilon^{n}_{j-1} -2\upsilon^{n}_{j+1} +\upsilon^{n}_{j+2}}{\Delta x^3}  \right)\right).  \\
	\end{multline*}


Since we have assumed that $\eta$ and $\upsilon$ are fourier nodes, we replace the finite difference approximations with the appropriate factors from \eqref{eqn:FDfactorlist}. After some rearranging we get that

\begin{equation*}
\eta^{n+1}_j = \eta^{n-1}_j - \Delta t \left(U  \frac{i \sin\left(k \Delta x\right)}{\Delta x}\eta^n_j + H\frac{i \sin\left(k \Delta x\right)}{\Delta x} \upsilon^n_j \right) 
\end{equation*}
and
\begin{multline*}
\upsilon^{n+1}_j  =  \upsilon^{n-1}_j  -  \frac{3 \Delta x^2\Delta t}{3 \Delta x^2 -2{H^2} \left( \cos\left(k \Delta x\right) - 1 \right)}\bigg( g \frac{i \sin\left(k \Delta x\right)}{\Delta x}     \bigg) \eta^n_j\\ + U\frac{i \Delta t \sin\left(k \Delta x\right)}{\Delta x} \upsilon^n_j.  \\
\end{multline*}
 
We can rewrite this in matrix vector form as
\begin{equation}
\begin{bmatrix}
\eta^{n+1}_j \\
\upsilon^{n+1}_j\\
\eta^{n}_j \\
\upsilon^{n}_j
\end{bmatrix} = \matr{E}
\begin{bmatrix}
\eta^{n}_j \\
\upsilon^{n}_j\\
\eta^{n-1}_j \\
\upsilon^{n-1}_j
\end{bmatrix},
\end{equation}
where 
\begin{equation*}
\matr{E}_{\mathcal{D}} = \begin{bmatrix}
-  \dfrac{2 i\Delta t }{\Delta x} U\sin\left(k \Delta x\right)  & -  \dfrac{2 i\Delta t}{\Delta x} H \sin\left(k \Delta x\right)  & 1 &0 \\ \\
-\dfrac{6 gi \Delta x\Delta t}{3 \Delta x^2 -2{H^2} \left( \cos\left(k \Delta x\right) - 1 \right)}{ \sin\left(k \Delta x\right)}  & -\dfrac{2i \Delta t }{\Delta x} U \sin\left(k \Delta x\right)  & 0 &1 \\
1  & 0  &0 &0 \\
0  & 1  &0 &0 
\end{bmatrix} .
\end{equation*}

This is the evolution matrix $\matr{E}_{\mathcal{D}}$ and if its spectral radius is at most $1$ then $\mathcal{D}$ is stable.

After performing the same process for $\mathcal{W}$ we get the following matrix equation

\begin{equation}
\begin{bmatrix}
\eta^{n+1}_j \\
\upsilon^{n+1}_j\\
\eta^n_j \\
\upsilon^n_j
\end{bmatrix}= \matr{E}_{\mathcal{W}}  \begin{bmatrix}
\eta^{n}_j \\
\upsilon^{n}_j\\
\eta^{n-1}_j \\
\upsilon^{n-1}_j
\end{bmatrix}.
\end{equation}
where
\begin{equation}
\matr{E}_{\mathcal{W}} = \begin{bmatrix}
{E}_{\mathcal{W}}^{0,0} & {E}_{\mathcal{W}}^{0,1} & 0 & - \dfrac{\Delta t}{\Delta x}H\frac{i\sin\left(k\Delta x\right)}{2} \\
{E}_{\mathcal{W}}^{1,0} & -\dfrac{2i \Delta t }{\Delta x} U \sin\left(k \Delta x\right)&0 & 1 \\
1&0&0&0\\
0&1&0&0
\end{bmatrix}
\end{equation}
with
\begin{align*}
&{E}_{\mathcal{W}}^{0,0} = 1 - \frac{\Delta t}{\Delta x}\left(-\dfrac{6 gi \Delta x\Delta t}{3 \Delta x^2 -2{H^2} \left( \cos\left(k \Delta x\right) - 1 \right)}{ \sin\left(k \Delta x\right)}\right)H\frac{i\sin\left(k\Delta x\right)}{2} \\ &- \frac{\Delta t}{\Delta x}U\left(\left(i\sin\left(k\Delta x\right)\right) - \frac{\Delta t}{\Delta x}U\left(\cos\left(k\Delta x\right) - 1\right)\right), \\
&{E}_{\mathcal{W}}^{0,1} = - \frac{\Delta t}{\Delta x} \left[H\frac{i\sin\left(k\Delta x\right)}{2}\left( 1 -\dfrac{2i \Delta t }{\Delta x} U \sin\left(k \Delta x\right) \right)   -U\left(\frac{\Delta t}{\Delta x}H\left(\cos\left(k\Delta x\right) - 1\right)\right) \right],\\
& {E}_{\mathcal{W}}^{1,0} =-\dfrac{6 gi \Delta x\Delta t}{3 \Delta x^2 -2{H^2} \left( \cos\left(k \Delta x\right) - 1 \right)}{ \sin\left(k \Delta x\right)}.
\end{align*}


If the evolution matrix $\matr{E}_{\mathcal{W}}$ has a spectral radius less than or equal to $1$ then $\mathcal{W}$ is stable.

It can be seen that we generated this evolution matrix $\matr{E}$ for each of the FDVM and FEVM. In particular we have that

\begin{align*}
&\matr{E}_{1} = \matr{I} - \Delta t \matr{F}_1 \\
&\matr{E}_{FD2} = \matr{I} - \Delta t \matr{F}_{FD2} + \frac{1}{2} \Delta t^2 \matr{F}_{FD2}^2 \\
&\matr{E}_{FEM2} =  \matr{I} - \Delta t \matr{F}_{FEM2} + \frac{1}{2} \Delta t^2 \matr{F}_{FEM2}^2\\
&\matr{E}_{3} = \matr{I} - \Delta t \matr{F}_{3} + \frac{1}{2} \Delta t^2 \matr{F}_3^2 - \frac{1}{6} \Delta t^3 \matr{F}_3^3. \\
\end{align*}

For the FDVM and FEVM the matrix equation is a bit simpler

\begin{equation}
\begin{bmatrix}
\eta \\
\upsilon\\
\end{bmatrix}^{n+1}_j = \matr{E}  \begin{bmatrix}
\eta\\
\upsilon\
\end{bmatrix}^{n}_j .
\end{equation}
As with the finite difference methods if the spectral radius of the evolution matrix is at most $1$ then the scheme is stable.

We will now present the results of our analysis of the stability of all these methods for various $U$, $H$ and $k$ values. 

\subsection{Results}
We will demonstrate that these finite difference methods possess Von Neumann stability numerically. We do this by calculating the spectral radius of the growth matrices numerically for various fixed $H$ and $k$ values and demonstrate the behaviour of this spectral radius as $\Delta x$ changes. We use the CFL condition to determine $\Delta t$ given $\Delta x$, and in particular we again have $\Delta t =   \left( 0.5 / \left(U + \sqrt{gH}\right) \right) {\Delta x} $. We first show the results for $U = 0$ so that we  can demonstrate the stability of the FDVM and FEVM as well. We then allow various $U$ values for which we do not have the results for the FDVM and FEVM.

\subsubsection{Quiescent Fluid}
This is the situation in which we are most interested in for the purposes of ocean modelling. Most of the numerical experiments we perform later will occur in this region where the water is still with waves propagating on top. This is also the scenario in which the growth matrices for the FDVM and FEVM were calculated and thus we can only demonstrate the stability of all methods in this region. Although of course as mentioned previously the FDVM and FEVM inherit their stability from the finite volume method at their core.

The spectral radius for a range of $\Delta x$ values was plotted in Figure~\ref{fig:Stabu=0} for all numerical methods in this thesis. The representative values of $kH =0.5$ and $kH = 2.5$ were the chosen due to their use in the dispersion error analysis for the stability results plotted in Figure~\ref{fig:DispErrMeth1}. These values were representative of the results we observed for other scenarios and these values cover the range of physical scenarios we are interested in. 

Our results demonstrate that all numerical methods satisfy the stability condition for a range of $kH$ values with $U=0$ as all methods have growth matrices with spectral radius less than or equal to $1$. Indeed this is what we found generally for all these methods for all our investigated values of $hK$.

We note that both the second-order FDVM ({\color{red} \solidrule}) and FEVM ({\color{blue} \solidrule}) have very similar spectral radius values such that their plots overlap and only the curve for the FEVM ({\color{blue} \solidrule}) is visible. We also observe similar behaviour for the two second-order finite difference methods $\mathcal{D}$ ({\color{violet!80!white} \solidrule}) and $\mathcal{W}$ ({\color{orange} \solidrule}) so that only the curve for $\mathcal{W}$ ({\color{orange} \solidrule}) is visible.

We observe that the spectral radius for the second-order finite difference methods $\mathcal{D}$ and $\mathcal{W}$ are consistently $1$ when $U=0$ for various $hK$ and $
k\Delta x$ values. This can be seen in Table~\ref{tab:Averageofspectralradiusu=0}, where the average of the spectral radius for $\mathcal{D}$ and $\mathcal{W}$ over various $k \Delta x$ values is $1$ plus a number which is just the accumulation of round-off errors caused by performing this analysis numerically.
%
\begin{figure}
	\centering
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp5/figures/stabilityu=0kh0p5.pdf}
		\subcaption*{\hspace{10 mm}$U =0$, $H = 1 $ and $k = 0.5$}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp5/figures/stabilityu=0kh2p5.pdf}
		\subcaption*{\hspace{10 mm}$U =0$, $H = 1 $ and $k = 2.5$}
	\end{subfigure}
	\caption{Spectral radius of growth matrix $\matr{E}$ for first-order FDVM ({\color{green!60!black} \solidrule}), second-order FDVM({\color{red} \solidrule}), second-order FEVM ({\color{blue} \solidrule}), third-order FDVM ({\solidrule}), $\mathcal{D}$ ({\color{violet!80!white} \solidrule}) and $\mathcal{W}$ ({\color{orange} \solidrule}) .}
	\label{fig:Stabu=0}
\end{figure}
%
\begin{table}
	\centering
	\begin{tabular}{l  c  c}
		Method & $kH$& Average\\
		\hline && \\
		$\mathcal{D}$& $0.5$ & $1+ 4\times 10^{-16}$  \\
		$\mathcal{D}$& $2.5$ & $1+ 4\times 10^{-16}$  \\
		\hline \\
		$\mathcal{W}$& $0.5$ & $1+ 4\times 10^{-16}$  \\
		$\mathcal{W}$& $2.5$ & $1+ 4\times 10^{-16}$ 
	\end{tabular}
	\caption{Average of $\rho\left(\matr{E}\right)$ over all $\Delta x$ values for the second-order finite difference methods when $U=0$.}
	\label{tab:Averageofspectralradiusu=0}
\end{table}
\subsubsection{Non-zero Mean Flow} 
The situation of waves on still water is certainly the most common situation in ocean modelling, however there are scenarios that can arise where certain regions have a mean flow and we are interested in the waves on top, such as undular bores. Therefore we must also demonstrate stability in this case for the two finite difference methods. Since the dispersion relation analysis that derived the evolution matrix for the FDVM and FEVM assumed $U=0$ we do not demonstrate their stability here. 

We have investigated the behaviour of the spectral radius of the growth matrix for various values of $U$, $kH$ and $\Delta x$. We present the results for $U =1$ with $kH =0.5$ and $2.5$ in Figure~\ref{fig:Stabu=1}. These values were chosen because they are representative of the behaviour for both methods for most values of $U$ and $kH$, and because they match the previous values in the dispersion analysis above. 

These results demonstrate that the naive second-order method $\mathcal{D}$ is still stable even with a background mean flow, with a spectral radius that is consistently $1$. This is demonstrated in Table~\ref{tab:Averageofspectralradiusu=1} as well where the average spectral radius is $1$ plus a number that is just round-off error. This behaviour was consistent for various $U$, $kH$ and $\Delta x$ values provided the CFL condition was used to determine $\Delta t$. Therefore this method is stable as desired for a range of flow scenarios. 

Unfortunately the Lax-Wendroff finite difference method $\mathcal{W}$ is no longer stable anywhere with growth factors that are consistently larger than $1$ although it approaches stability as $\Delta x \rightarrow 0$. This is evident in Table \ref{tab:Averageofspectralradiusu=1} where the average spectral radius is larger than $1$ by significantly more than round-off error. By modifying the parameters we can increase the spectral radius as desired. However, the parameters do not follow some simple rule and their behaviour is quite complicated. Although it is the case that our largest $\Delta x$ value did correspond to our largest spectral radius. However, the interaction between the spectral radius, $hK$ and $U$ is not so obvious. Since the spectral radius was consistently larger than $1$ when $U \neq 0$ this means the Lax-Wendroff method is not stable unless $U=0$. Although the growth factors are only marginally greater than $1$ for most situations and so the instabilities may not be apparent when performing numerical experiments, as we demonstrate in Chapter []. 
\begin{figure}
	\centering
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp5/figures/stabilityu=1kh0p5.pdf}
		\subcaption*{\hspace{10 mm}$U =1$, $H = 1 $ and $k = 0.5$}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\includegraphics[width=\textwidth]{./chp5/figures/stabilityu=1kh2p5.pdf}
		\subcaption*{\hspace{10 mm}$U =1$, $H = 1 $ and $k = 2.5$}
	\end{subfigure}
	\caption{Spectral radius of growth matrix $\matr{E}$ for $\mathcal{D}$ ({\color{violet!80!white} \solidrule}) and $\mathcal{W}$ ({\color{orange} \solidrule}) .}
	\label{fig:Stabu=1}
\end{figure}


\begin{table}
	\centering
	\begin{tabular}{l  c  c}
		Method & $kH$& Average\\
		\hline && \\
		$\mathcal{D}$ & $0.5$ & $1+ 4\times 10^{-16}$  \\
		$\mathcal{D}$ & $2.5$ & $1+ 4\times 10^{-16}$  \\
		\hline \\
		$\mathcal{W}$ & $0.5$ & $1+ 6\times 10^{-3}$  \\
		$\mathcal{W}$ & $2.5$ & $1+ 3\times 10^{-3}$   \\
	\end{tabular}
	\caption{Average of $\rho\left(\matr{E}\right)$ over all $\Delta x$ values for the second-order finite difference methods when $U=1$.}
	\label{tab:Averageofspectralradiusu=1}
\end{table}